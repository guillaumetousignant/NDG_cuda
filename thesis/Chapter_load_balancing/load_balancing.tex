\chapter{Load Balancing}\label{chapter:load_balancing}

A well made multi-block mesh can distribute the work evenly between the different worker processes
without needing runtime adjustment if the topology and areas of more expensive computation stay the
same during the whole computation. This is complicated by the fact that, as seen in
Chapter~\ref{chapter:adaptive_mesh_refinement}, the mesh elements can increase their polynomial
order and split into multiple smaller elements in areas where the solution accuracy is estimated to
be unsatisfactory. Unless the regions of interest happen to be evenly distributed between the
different processes, this will lead to an imbalance as some processes are left with more elements,
or higher-order elements, within their domain as illustrated in Figure~\ref{fig:load_imbalance_lb}.

\begin{figure}[H]
    \centering
    \subfloat[Mesh before refining]
    {\includegraphics[width=0.45\textwidth]{Chapter_load_balancing/media/load_imbalance_initial}\label{fig:mesh_imbalance_initial_lb}}
    \hfill
    \subfloat[Mesh after refining]
    {\includegraphics[width=0.45\textwidth]{Chapter_load_balancing/media/load_imbalance}\label{fig:mesh_imbalance_after_refinement_lb}}
    \caption{Load imbalance: The elements have split unequally in the two worker
        \acrshortpl{acr:GPU},  purple and blue, one having a higher computational load. (a) Before
        refining (b) After refining}\label{fig:load_imbalance_lb}
\end{figure}

The wall clock time of the simulation will be driven by the most heavily loaded process, as the
processes have to synchronise at each time step. The more lightly loaded processes will simply wait
for the other to finish computing.

In order to maintain good performance as the mesh is refined, we will need to perform dynamic load
balancing. Dynamic load balancing seeks to even out the computational load between the different
processes. The algorithm for load balancing needs to be fast, to be executed often and to keep the
mesh optimal for a longer period without overshadowing the solution time. The worker processes in
this work use \acrshortpl{acr:GPU} for their computations. Because transfers between
\acrshortpl{acr:GPU} are expensive, the algorithm needs to limit transfers both during the load
balancing process and during computation afterwards. The workers are made up of one
\acrshort{acr:CPU} core and one entire \acrshort{acr:GPU}. This means that the worker's processing
power is mostly generated by the \acrshort{acr:GPU}, and the algorithm needs to use it as much as
possible. The algorithm will need to have as many parts as possible running on the
\acrshort{acr:GPU}, in parallel. Finally, the algorithm needs to use as little additional
\acrshort{acr:GPU} memory as possible, as these processors have limited memory, especially compared
to \acrshortpl{acr:CPU}.

The algorithm needs to select which elements to send from one \acrshort{acr:GPU} to another. Many
such algorithms exist, notably graph-based algorithms~\cite{Karypis1998} and one-dimensional
algorithms~\cite{Pinar2004}, often called \textit{\acrfull{acr:CCP}}. \Acrlong{acr:CCP} will be used
here for its relative speed. This will require a scheme to transform our domain from two-dimensional
space to one-dimensional space, as required by the algorithm.

Here, the repartitioning scheme uses \textit{\acrfullpl{acr:SFC}}, more specifically the Hilbert
Curve. \Acrshortpl{acr:SFC} map multi-dimensional space to one-dimensional space. This space can be
partitioned in segments, and upon change of the size of these segments elements can then be sent or
received from the ends of these segments. In addition, these curves are fast to generate, use low
memory, and maximise locality. Elements that are close in curve space will also be close by in the
space used for computations. This limits the number of interfaces between processes.

\section{Hilbert Curve}\label{section:load_balancing:hilbert_curve}

The Hilbert curve, developed by D. Hilbert~\cite{Hilbert1891}, is a specific kind of space-filling
curve as described by G. Peano~\cite{Peano1890}. This curve works for 2D domains with equal and
power of two resolution in x and y. Some newer research~\cite{Haverkort2011} shows how such curves
can be expanded to three dimensions, and arbitrary domains.

\begin{figure}[H]
    \centering
    \subfloat[First level]
    {\includesvg[width=0.3\textwidth]{Chapter_load_balancing/media/hilbert_curve_K2}\label{fig:hilbert_k2}}
    \hfill
    \subfloat[Second level]
    {\includesvg[width=0.3\textwidth]{Chapter_load_balancing/media/hilbert_curve_K4}\label{fig:hilbert_k4}}
    \hfill
    \subfloat[Third level]
    {\includesvg[width=0.3\textwidth]{Chapter_load_balancing/media/hilbert_curve_K8}\label{fig:hilbert_k8}}
    \caption{Hilbert curve: The first thee Hilbert curves. (a) \(2\times2\) (b) \(4\times4\) (c) \(8\times8\)}\label{fig:hilbert_curves}
\end{figure}

Figure~\ref{fig:hilbert_curves} shows the first three levels of the Hilbert curve. The curve
successfully maps our 2D domain to a 1D one along the curve. That 1D domain can then be partitioned
between the different worker \acrshortpl{acr:GPU}. As illustrated in the figure, the elements have
good locality and no jumps exist. Wherever the curve is cut, elements on the resulting segments are
close together. This is the first desirable property of the curve for this program, as we aim to
reduce the contact area between the mesh blocks dispatched to each \acrshort{acr:GPU}. The iterative
nature of those curves is also apparent when put side by side. Each increasing level of the curve
follows the general path of the previous curve. Iteration is one of the possible ways to generate
this curve. The Hilbert curve is used to generate the initial meshes used by the program, as well as
to re-number elements when the mesh refines.

\subsection{Generation}\label{subsection:load_balancing:hilbert_curve:generation}

I think we need a sentence distinguishing H A R B or saying at least that the state identifies the 
type of a cell within the topology of the Hilbert curve or something like that


We choose a table-driven algorithm to generate meshes. Each element has one of four possible
\textit{states} \(s\): \(s \in \left \{H, A, R, B \right \} \). The state of an element represents
the local pattern of the curve inside the element. This state determines the state and ordering of
the four children elements obtained when increasing the level of the curve. The four states and
their resulting children are shown in Figure~\ref{fig:hilbert_splits}.

\begin{figure}[H]
    \centering
    \subfloat[H splitting: \newline \(A, H, H, B\)]
    {\includesvg[width=0.23\textwidth]{Chapter_load_balancing/media/hilbert_split_H}\label{fig:hilbert_split_H}}
    \hfill
    \subfloat[A splitting: \newline \(H, A, A, R\)]
    {\includesvg[width=0.23\textwidth]{Chapter_load_balancing/media/hilbert_split_A}\label{fig:hilbert_split_A}}
    \hfill
    \subfloat[R splitting: \newline \(B, R, R, A\)]
    {\includesvg[width=0.23\textwidth]{Chapter_load_balancing/media/hilbert_split_R}\label{fig:hilbert_split_R}}
    \hfill
    \subfloat[B splitting: \newline \(R, B, B, H\)]
    {\includesvg[width=0.23\textwidth]{Chapter_load_balancing/media/hilbert_split_B}\label{fig:hilbert_split_B}}
    \caption{The four states splitting, with their children's state and ordering.}\label{fig:hilbert_splits}
\end{figure}

\noindent
When put together, and assigning \(H\) as the first state of the mesh, the mesh can be iteratively
constructed to the required level as shown in Figure~\ref{fig:hilbert_levels}.

\begin{figure}[H]
    \centering
    \subfloat[Level 0]
    {\includesvg[width=0.3\textwidth]{Chapter_load_balancing/media/hilbert_level_0}\label{fig:hilbert_l0}}
    \hfill
    \subfloat[Level 1]
    {\includesvg[width=0.3\textwidth]{Chapter_load_balancing/media/hilbert_level_1}\label{fig:hilbert_l1}}
    \hfill
    \subfloat[Level 2]
    {\includesvg[width=0.3\textwidth]{Chapter_load_balancing/media/hilbert_level_2}\label{fig:hilbert_l2}}
    \caption{First levels of the Hilbert curve with statuses \(s\) (\(s \in \left \{ H, A , B , R \right \} \)).}\label{fig:hilbert_levels}
\end{figure}

\noindent
This construction can be summarised in Tables~\ref{table:children_state}
and~\ref{table:children_ordering}. The ordering of the children elements is from the bottom left
element, in counter-clockwise order as shown in Figure~\ref{fig:child_order}. 

\begin{figure}[H]
    \centering
    \includesvg[width=0.3\textwidth]{Chapter_load_balancing/media/child_order}
    \caption{Child numbering: The \(j = 0, 1, 2, 3\) children of an element, used to assign states and ordering.}\label{fig:child_order}
\end{figure}

\noindent
These tables are implemented directly in the code, with the state defined as an enumeration from 0
to 3 and the tables as arrays. The state is used as an index for the arrays to get the resulting
ordering and states. This gives the state \(S(s, j)\) of the j\textsuperscript{th} child element of
a parent element as a function of the state \(s\) of the parent element. The same goes for the
ordering \(p\) of the children, \(P(s, j)\).

\begin{table}[H]
    \begin{center}
        \begin{tabular}{ c | c c c c} 
            \(S( s, j )\) & \(j = 0\) & \(j = 1\) & \(j = 2\) & \(j = 3\)  \\
            \hline
            \(s = H\) & \textcolor{vs_red}{\(A\)} & \textcolor{vs_red}{\(B\)} & \textcolor{vs_red}{\(H\)} & \textcolor{vs_red}{\(H\)} \\ 
            \(s = A\) & \textcolor{vs_blue}{\(H\)} & \textcolor{vs_blue}{\(A\)} & \textcolor{vs_blue}{\(A\)} & \textcolor{vs_blue}{\(R\)} \\
            \(s = R\) & \textcolor{vs_teal}{\(R\)} & \textcolor{vs_teal}{\(R\)} & \textcolor{vs_teal}{\(B\)} & \textcolor{vs_teal}{\(A\)} \\
            \(s = B\) & \textcolor{vs_plum}{\(B\)} & \textcolor{vs_plum}{\(H\)} & \textcolor{vs_plum}{\(R\)} & \textcolor{vs_plum}{\(B\)} \\
        \end{tabular}
    
        \caption{Children element state table: child state \(S\), with \(s\) being the state of the parent element and \(j\) being the j\textsuperscript{th} child.}\label{table:children_state}
    \end{center}
\end{table}

\begin{table}[H]
    \begin{center}
        \begin{tabular}{ c | c c c c} 
            \(P( s, j )\) & \(j = 0\) & \(j = 1\) & \(j = 2\) & \(j = 3\)  \\
            \hline
            \(s = H\) & \textcolor{vs_red}{\(0\)} & \textcolor{vs_red}{\(3\)} & \textcolor{vs_red}{\(2\)} & \textcolor{vs_red}{\(1\)} \\ 
            \(s = A\) & \textcolor{vs_blue}{\(0\)} & \textcolor{vs_blue}{\(1\)} & \textcolor{vs_blue}{\(2\)} & \textcolor{vs_blue}{\(3\)} \\
            \(s = R\) & \textcolor{vs_teal}{\(2\)} & \textcolor{vs_teal}{\(1\)} & \textcolor{vs_teal}{\(0\)} & \textcolor{vs_teal}{\(3\)} \\
            \(s = B\) & \textcolor{vs_plum}{\(2\)} & \textcolor{vs_plum}{\(3\)} & \textcolor{vs_plum}{\(0\)} & \textcolor{vs_plum}{\(1\)} \\
        \end{tabular}
        
        \caption{Children element order table: child order \(P\), with \(s\) being the state of the parent element and \(j\) being the j\textsuperscript{th} child.}\label{table:children_ordering}
    \end{center}
\end{table}

This table-driven approach has the added benefit of working seamlessly in parallel, as each element
can generate its children using nothing more than its own order.

Without \acrlong{acr:AMR}, no more work is needed. The elements do not even need to store their
state, as the compact numbering of the elements is the result of the Hilbert curve. The mesh
generator included with the program works this way, creating a uniform power of two sized 2D mesh
numbered according to the Hilbert curve. The mesh generator uses the standard \acrshort{acr:CGNS}
format. The meshes generated in this way can be used directly by the program on a single
\acrshort{acr:GPU}, or split into multiple blocks using the provided mesh partitioner. The mesh
partitioner can split any single-block \acrshort{acr:CGNS} mesh into a multi-block mesh, which can
then be used by the main program running on multiple \acrshortpl{acr:GPU}.

\subsection{Refinement}\label{section:load_balancing:hilbert_curve:refinement}

The same iterative process is used to refine elements. The parent state dictates the state and
ordering of its children. Correct ordering is critical to maintaining good locality between elements
as the mesh refines and non-conforming interfaces are created. Figure~\ref{fig:hilbert_refining}
shows a mesh block refining, where the element \(6\) splits into four smaller elements. The ordering
of the children elements must follow the Hilbert curve to maintain the locality of the mesh.

\begin{figure}[H]
    \centering
    \subfloat[Before refining]
    {\includesvg[width=0.4\textwidth]{Chapter_load_balancing/media/mesh_1_before_adaptivity0}\label{fig:hilbert_before}}
    \hfill
    \subfloat[After refining]
    {\includesvg[width=0.4\textwidth]{Chapter_load_balancing/media/mesh_1_after_adaptivity0}\label{fig:hilbert_after}}
    \caption{Mesh refinement Hilbert curve: One element refining. (a) Before splitting (b) After splitting}\label{fig:hilbert_refining}
\end{figure}

This process assumes knowledge of each element's status. However, the main solver program is
designed to accept standard \acrshort{acr:CGNS} meshes as an input. The \acrshort{acr:CGNS} format
does not provide status information. Furthermore, the program can accept any 2D unstructured mesh
using the format, which may not be numbered according to a Hilbert curve. 

It is therefore necessary to deduce the status of elements when reading a mesh file.
Figure~\ref{fig:hilbert_l2} gives a hint of a possible way to do this. For an element \(k\), the
curve goes from element \(k - 1\) to element \(k\), and then from element \(k\) to element \(k +
1\). When entering element \(k\) from element \(k - 1\), the curve will pass through one of the four
sides of element \(k\). The same goes for the curve leaving element \(k\) towards element \(k + 1\).
Following the curve, each combination of entrance side and exit side corresponds to a single state.
For example, the curve entering from the left side of the element and exiting through the top side
always has the state \(A\). This is confirmed by examining other levels of the Hilbert curve. The
same can be deduced for the first and last elements, using only the exiting and entering side,
respectively. Using this information, we can create a 2D matrix of state as a function of entering
and exiting side for elements (Table~\ref{table:guess_table_incomplete}), and 1D matrices for the
first and last elements (Table~\ref{table:guess_table_first}).

\begin{table}[H]
    \begin{center}
        \begin{tabular}{ c | c c c c} 
            & \begin{tabular}{c} \includesvg[width=0.1\textwidth]{Chapter_load_balancing/media/out_0} \end{tabular} & \begin{tabular}{c} \includesvg[width=0.1\textwidth]{Chapter_load_balancing/media/out_1} \end{tabular} & \begin{tabular}{c} \includesvg[width=0.1\textwidth]{Chapter_load_balancing/media/out_2} \end{tabular} & \begin{tabular}{c} \includesvg[width=0.1\textwidth]{Chapter_load_balancing/media/out_3} \end{tabular} \\
            \hline
            \begin{tabular}{c} \includesvg[width=0.1\textwidth]{Chapter_load_balancing/media/in_0} \end{tabular} & \begin{tabular}{c}       \end{tabular} & \begin{tabular}{c} \(H\) \end{tabular} & \begin{tabular}{c} \(A\) \end{tabular} & \begin{tabular}{c} \(A\) \end{tabular} \\ 
            \begin{tabular}{c} \includesvg[width=0.1\textwidth]{Chapter_load_balancing/media/in_1} \end{tabular} & \begin{tabular}{c} \(B\) \end{tabular} & \begin{tabular}{c}       \end{tabular} & \begin{tabular}{c} \(R\) \end{tabular} & \begin{tabular}{c} \(R\) \end{tabular} \\
            \begin{tabular}{c} \includesvg[width=0.1\textwidth]{Chapter_load_balancing/media/in_2} \end{tabular} & \begin{tabular}{c} \(B\) \end{tabular} & \begin{tabular}{c} \(B\) \end{tabular} & \begin{tabular}{c}       \end{tabular} & \begin{tabular}{c} \(R\) \end{tabular} \\
            \begin{tabular}{c} \includesvg[width=0.1\textwidth]{Chapter_load_balancing/media/in_3} \end{tabular} & \begin{tabular}{c} \(H\) \end{tabular} & \begin{tabular}{c} \(H\) \end{tabular} & \begin{tabular}{c} \(A\) \end{tabular} & \begin{tabular}{c}       \end{tabular} \\
        \end{tabular}
    
        \caption{Element state deduction table: Element state as a function of curve entrance and
            exit side.}\label{table:guess_table_incomplete}
    \end{center}
\end{table}

\begin{table}[H]
    \begin{center}
        \begin{tabular}{ c c c c} 
            \begin{tabular}{c} \includesvg[width=0.1\textwidth]{Chapter_load_balancing/media/out_0} \end{tabular} & \begin{tabular}{c} \includesvg[width=0.1\textwidth]{Chapter_load_balancing/media/out_1} \end{tabular} & \begin{tabular}{c} \includesvg[width=0.1\textwidth]{Chapter_load_balancing/media/out_2} \end{tabular} & \begin{tabular}{c} \includesvg[width=0.1\textwidth]{Chapter_load_balancing/media/out_3} \end{tabular} \\
            \midrule
            \begin{tabular}{c} \(B\) \end{tabular} & \begin{tabular}{c} \(H\) \end{tabular} & \begin{tabular}{c} \(A\) \end{tabular} & \begin{tabular}{c} \(R\) \end{tabular} \\ 
        \end{tabular}
    
        \caption{First element state deduction table: Element state as a function of curve exit
            side.}\label{table:guess_table_first}
    \end{center}
\end{table}

\begin{table}[H]
    \begin{center}
        \begin{tabular}{ c | c} 
            \begin{tabular}{c} \includesvg[width=0.1\textwidth]{Chapter_load_balancing/media/in_0} \end{tabular} & \begin{tabular}{c} \(A\) \end{tabular} \\ 
            \begin{tabular}{c} \includesvg[width=0.1\textwidth]{Chapter_load_balancing/media/in_1} \end{tabular} & \begin{tabular}{c} \(R\) \end{tabular} \\
            \begin{tabular}{c} \includesvg[width=0.1\textwidth]{Chapter_load_balancing/media/in_2} \end{tabular} & \begin{tabular}{c} \(B\) \end{tabular} \\
            \begin{tabular}{c} \includesvg[width=0.1\textwidth]{Chapter_load_balancing/media/in_3} \end{tabular} & \begin{tabular}{c} \(H\) \end{tabular} \\
        \end{tabular}
    
        \caption{Last element state deduction table: Element state as a function of curve entrance side.}\label{table:guess_table_last}
    \end{center}
\end{table}

A few combinations are still undefined in the matrix. They represent the cases where the curve
enters and leaves through the same side of the element. These cases should not occur with correct
Hilbert curves. However, nonconforming geometries created while refining, or meshes created without
using a Hilbert curve, may generate those geometries. Examining Figure~\ref{fig:hilbert_splits}, we
observe that for each status the first and last child elements occupy the same side. We match that
side in Figure~\ref{fig:hilbert_missing_splits} with the incoming and exiting sides of the undefined
cases.

\begin{figure}[H]
    \centering
    \subfloat[Bottom: \(H\)]
    {\includesvg[width=0.23\textwidth]{Chapter_load_balancing/media/inout_0}\label{fig:hilbert_missing_0}}
    \hfill
    \subfloat[Right: \(B\)]
    {\includesvg[width=0.23\textwidth]{Chapter_load_balancing/media/inout_1}\label{fig:hilbert_missing_1}}
    \hfill
    \subfloat[Top: \(R\)]
    {\includesvg[width=0.23\textwidth]{Chapter_load_balancing/media/inout_2}\label{fig:hilbert_missing_2}}
    \hfill
    \subfloat[Left: \(A\)]
    {\includesvg[width=0.23\textwidth]{Chapter_load_balancing/media/inout_3}\label{fig:hilbert_missing_3}}
    \caption{The four missing combinations: Each corresponds to a single state.}\label{fig:hilbert_missing_splits}
\end{figure}

We can then obtain the full matrix, given in Table~\ref{table:guess_table}.

% This is madness. The easiest way to vertically and horizontally center that doesn't use many
% packages or paragraphs of syntax is to enclose each cell in a tabular block. Then people wonder
% why I don't like Latex.
\begin{table}[H]
    \begin{center}
        \begin{tabular}{ c | c c c c} 
            & \begin{tabular}{c} \includesvg[width=0.1\textwidth]{Chapter_load_balancing/media/out_0} \end{tabular} & \begin{tabular}{c} \includesvg[width=0.1\textwidth]{Chapter_load_balancing/media/out_1} \end{tabular} & \begin{tabular}{c} \includesvg[width=0.1\textwidth]{Chapter_load_balancing/media/out_2} \end{tabular} & \begin{tabular}{c} \includesvg[width=0.1\textwidth]{Chapter_load_balancing/media/out_3} \end{tabular} \\
            \hline
            \begin{tabular}{c} \includesvg[width=0.1\textwidth]{Chapter_load_balancing/media/in_0} \end{tabular} & \begin{tabular}{c} \(H\) \end{tabular} & \begin{tabular}{c} \(H\) \end{tabular} & \begin{tabular}{c} \(A\) \end{tabular} & \begin{tabular}{c} \(A\) \end{tabular} \\ 
            \begin{tabular}{c} \includesvg[width=0.1\textwidth]{Chapter_load_balancing/media/in_1} \end{tabular} & \begin{tabular}{c} \(B\) \end{tabular} & \begin{tabular}{c} \(B\) \end{tabular} & \begin{tabular}{c} \(R\) \end{tabular} & \begin{tabular}{c} \(R\) \end{tabular} \\
            \begin{tabular}{c} \includesvg[width=0.1\textwidth]{Chapter_load_balancing/media/in_2} \end{tabular} & \begin{tabular}{c} \(B\) \end{tabular} & \begin{tabular}{c} \(B\) \end{tabular} & \begin{tabular}{c} \(R\) \end{tabular} & \begin{tabular}{c} \(R\) \end{tabular} \\
            \begin{tabular}{c} \includesvg[width=0.1\textwidth]{Chapter_load_balancing/media/in_3} \end{tabular} & \begin{tabular}{c} \(H\) \end{tabular} & \begin{tabular}{c} \(H\) \end{tabular} & \begin{tabular}{c} \(A\) \end{tabular} & \begin{tabular}{c} \(A\) \end{tabular} \\
        \end{tabular}
    
        \caption{Element state deduction table: Element state as a function of curve entrance and
            exit sides.}\label{table:guess_table}
    \end{center}
\end{table}

Until now, we assumed the elements were axis-aligned, and numbered such that their first edge is at
the bottom. This is important, as the elements number their children from their bottom left, in a
counter-clockwise order, shown in Figure~\ref{fig:node_order_normal}. If an element's first edge is
not at the bottom as in Figure~\ref{fig:node_order_rotated}, the wrong ordering will be given to
refining elements, as in Figure~\ref{fig:hilbert_l2_r}. Figure~\ref{fig:hilbert_l2_r} does not match
the correct Hilbert curve in Figure~\ref{fig:hilbert_l2}. Since elements can be oriented in any
direction in meshes, this situation is expected to happen. The following examples use elements
numbered such that their first side is not at the bottom, but at the right, as shown in
Figure~\ref{fig:node_order_rotated}.

\begin{figure}[H]
    \centering
    \subfloat[Upright element]
    {\includesvg[width=0.42\textwidth]{Chapter_load_balancing/media/node_order}\label{fig:node_order_normal}}
    \hfill
    \subfloat[Rotated element]
    {\includesvg[width=0.42\textwidth]{Chapter_load_balancing/media/node_order_r}\label{fig:node_order_rotated}}
    \caption{Element rotation: The numbering of the nodes of an element can affect its refinement. (a) Expected orientation (b) Unexpected orientation}\label{fig:node_order}
\end{figure}

\begin{figure}[H]
    \centering
    \subfloat[Before refining]
    {\includesvg[width=0.4\textwidth]{Chapter_load_balancing/media/hilbert_level_1_r}\label{fig:hilbert_l1_r}}
    \hfill
    \subfloat[After refining]
    {\includesvg[width=0.4\textwidth]{Chapter_load_balancing/media/hilbert_level_2_r}\label{fig:hilbert_l2_r}}
    \caption{Refinement with rotated elements: The numbering is wrong when compared to the correct Hilbert curve from Figure~\ref{fig:hilbert_l2}. (a) Initial mesh (b) Refined mesh}\label{fig:hilbert_rotated}
\end{figure}

One might be tempted to deduce the element status in the local element referential instead.
Figure~\ref{fig:referentials} shows the same rotated element in the global referential and in its
local referential. Note that the entering and exiting sides of the Hilbert curve are not the same,
which will change the deduced state. Figure~\ref{fig:hilbert_l2_l} shows the result of one step of
refinement using the local referential instead of the global referential.
Figure~\ref{fig:local_referential} shows that even though there are no jumps, the correct Hilbert
curve shown in Figure~\ref{fig:hilbert_l2} is not attained.

\begin{figure}[H]
    \centering
    \subfloat[Global referential]
    {\includesvg[width=0.42\textwidth]{Chapter_load_balancing/media/global_referential}\label{fig:global_referential}}
    \hfill
    \subfloat[Local referential]
    {\includesvg[width=0.42\textwidth]{Chapter_load_balancing/media/local_referential}\label{fig:local_referential}}
    \caption{Different referentials: The different referentials will change the deduced state. (a) H (b) R}\label{fig:referentials}
\end{figure}

\begin{figure}[H]
    \centering
    \subfloat[Before refining]
    {\includesvg[width=0.4\textwidth]{Chapter_load_balancing/media/hilbert_level_1_l}\label{fig:hilbert_l1_l}}
    \hfill
    \subfloat[After refining]
    {\includesvg[width=0.4\textwidth]{Chapter_load_balancing/media/hilbert_level_2_l}\label{fig:hilbert_l2_l}}
    \caption{Refinement with rotated elements using local referential: This is not the next level curve, as seen in Figure~\ref{fig:hilbert_l2}. (a) Initial mesh (b) Refined mesh}\label{fig:hilbert_local}
\end{figure}

Both methods give wrong results when the elements are rotated compared to the first edge at the
bottom case. The solution is to compute the entering and exiting sides in global coordinates,
depending on the direction the curve goes in x and y. When splitting, the elements use their
rotation as an offset when numbering their children elements. The rotation of the elements is
defined as the number of quarter turns the element is rotated compared to the normal case, with the
first edge at the bottom. The refined mesh using this method is shown in
Figure~\ref{fig:hilbert_l2_c} and now has the correct Hilbert curve as in
Figure~\ref{fig:hilbert_l2}.

\begin{figure}[H]
    \centering
    \subfloat[Before refining]
    {\includesvg[width=0.4\textwidth]{Chapter_load_balancing/media/hilbert_level_1_r}\label{fig:hilbert_l1_c}}
    \hfill
    \subfloat[After refining]
    {\includesvg[width=0.4\textwidth]{Chapter_load_balancing/media/hilbert_level_2}\label{fig:hilbert_l2_c}}
    \caption{Refinement with rotation offset: The next level Hilbert curve is correct. (a) Initial mesh (b) Refined mesh}\label{fig:hilbert_correct}
\end{figure}

With this out of the way, it is possible to compute the rotation when the mesh is read, store it as
a member of the element class, and use it whenever the element splits to get the correct ordering.
The different elements split independently in parallel, and the Hilbert curve keeps the ordering
coherent. An element gets the new indices of its children by knowing how many elements split before
it on the curve to give a starting index and then using the table to order the individual children.

The mesh can be refined multiple times that way and the locality of the Hilbert curve can be
preserved. Even non-confirming interfaces do not create any jumps in the curve.
Figure~\ref{fig:mesh_1_after2} shows a mesh of initially \(K = 4 \times 4\) elements refined and
load balanced three times. The Hilbert curve is shown in green to assess the quality of the
ordering.

\begin{figure}[H]
    \centering
    \includesvg[width=0.95\textwidth]{Chapter_load_balancing/media/mesh_1_after2_MOD}
    \caption{Mesh refining: The elements follow mixed levels of the Hilbert curve, without jumps or discontinuities.}\label{fig:mesh_1_after2}
\end{figure}

\section{Workload Leveling}\label{section:load_balancing:workload_leveling}

Now that the problem can be partitioned in one dimension, we can begin redistributing elements to
level out the workload between the different worker \acrshortpl{acr:GPU}. We use \acrlong{acr:CCP},
where a linear list of \(N\) tasks \(i\) have associated weights \(w_i\). This list of tasks is then
split into \(P\) parts, equal to the number of workers \(P\). Each worker \(p\) has a capacity
\(c_p\), indicating the relative workload it can execute.

To repartition, each worker sums the total weight of the \(I_p\) tasks it contains, \(w_p\).

\begin{equation}
    w_p = \sum_{i = 0}^{I_p}w_i
\end{equation}

\noindent
The total amount of work in the problem \(W\) is obtained by adding up the total weights of each
worker.

\begin{equation}
    W = \sum_{p = 0}^{p}w_p
\end{equation}

\noindent
Similarly, the total capacity of the system is summed.

\begin{equation}
    C = \sum_{p = 0}^{P}c_p
\end{equation}

\noindent
The ideal workload \(w_{ideal,p}\) of a worker is given by:

\begin{equation} \label{equ:ideal_workload}
    w_{ideal,p} = W \frac{c_p}{C}.
\end{equation}

The load imbalance \(L\) of the system is defined as the maximum of each worker's load imbalance
\(l_p\). A worker's load imbalance is the ratio between its current workload and its ideal workload:

\begin{equation}
    l_{p} = \frac{w_p}{w_{ideal,p}},
\end{equation}

\begin{equation} \label{equ:load_imbalance}
    L = \max_{0 \leq p \leq P}{(l_{p})}.
\end{equation}

\noindent
The parallel load efficiency \(E\) is the reciprocal of the load imbalance:

\begin{equation}
    E = \frac{1}{L}.
\end{equation}

The new starting task \(i_{0, p}\) of the worker is given by the new total weight of the previous
workers.

\begin{equation}
    i_{0, p} = \sum_{j = 0}^{p - 1}w_{ideal,j}
\end{equation}

Tables~\ref{table:before_repartition} and~\ref{table:after_repartition} provide an example of
repartitioning between four workers using this method.

\begin{table}[H]
    \begin{center}
        \begin{tabular}{ | c | c | c | c | c | c | c | c | c | c | c | c | c | c | c | c | c | } 
            \hline
            worker \(p\) & \multicolumn{4}{c|}{\cellcolor{vs_lightgreen}0} & \multicolumn{4}{c|}{\cellcolor{vs_lightblue}1} & \multicolumn{4}{c|}{\cellcolor{vs_lightred}2} & \multicolumn{4}{c|}{\cellcolor{vs_lightplum}3}  \\
            \hline
            capacity \(c_p\) & \multicolumn{4}{c|}{\cellcolor{vs_lightgreen}2} & \multicolumn{4}{c|}{\cellcolor{vs_lightblue}2} & \multicolumn{4}{c|}{\cellcolor{vs_lightred}1} & \multicolumn{4}{c|}{\cellcolor{vs_lightplum}1}  \\
            \hline
            global id & \cellcolor{vs_lightgreen}0 & \cellcolor{vs_lightgreen}1 & \cellcolor{vs_lightgreen}2 & \cellcolor{vs_lightgreen}3 & \cellcolor{vs_lightblue}4 & \cellcolor{vs_lightblue}5 & \cellcolor{vs_lightblue}6 & \cellcolor{vs_lightblue}7 & \cellcolor{vs_lightred}8 & \cellcolor{vs_lightred}9 & \cellcolor{vs_lightred}10 & \cellcolor{vs_lightred}11 & \cellcolor{vs_lightplum}12 & \cellcolor{vs_lightplum}13 & \cellcolor{vs_lightplum}14 & \cellcolor{vs_lightplum}15 \\ 
            \hline
            local id i & \cellcolor{vs_lightgreen}0 & \cellcolor{vs_lightgreen}1 & \cellcolor{vs_lightgreen}2 & \cellcolor{vs_lightgreen}3 & \cellcolor{vs_lightblue}0 & \cellcolor{vs_lightblue}1 & \cellcolor{vs_lightblue}2 & \cellcolor{vs_lightblue}3 & \cellcolor{vs_lightred}0 & \cellcolor{vs_lightred}1 & \cellcolor{vs_lightred}2 & \cellcolor{vs_lightred}3 & \cellcolor{vs_lightplum}0 & \cellcolor{vs_lightplum}1 & \cellcolor{vs_lightplum}2 & \cellcolor{vs_lightplum}3 \\ 
            \hline
            weight \(w_i\) & \cellcolor{vs_lightgreen}1 & \cellcolor{vs_lightgreen}1 & \cellcolor{vs_lightgreen}1 & \cellcolor{vs_lightgreen}1 & \cellcolor{vs_lightblue}2 & \cellcolor{vs_lightblue}2 & \cellcolor{vs_lightblue}3 & \cellcolor{vs_lightblue}2 & \cellcolor{vs_lightred}2 & \cellcolor{vs_lightred}1 & \cellcolor{vs_lightred}2 & \cellcolor{vs_lightred}1 & \cellcolor{vs_lightplum}1 & \cellcolor{vs_lightplum}1 & \cellcolor{vs_lightplum}2 & \cellcolor{vs_lightplum}1 \\ 
            \hline
            total weight \(w_p\) & \multicolumn{4}{c|}{\cellcolor{vs_lightgreen}4} & \multicolumn{4}{c|}{\cellcolor{vs_lightblue}9} & \multicolumn{4}{c|}{\cellcolor{vs_lightred}6} & \multicolumn{4}{c|}{\cellcolor{vs_lightplum}5} \\ 
            \hline
            ideal weight \(w_{ideal,p}\) & \multicolumn{4}{c|}{\cellcolor{vs_lightgreen}8} & \multicolumn{4}{c|}{\cellcolor{vs_lightblue}8} & \multicolumn{4}{c|}{\cellcolor{vs_lightred}4} & \multicolumn{4}{c|}{\cellcolor{vs_lightplum}4} \\ 
            \hline
        \end{tabular}
    
        \caption{Problem before repartition: The workers have uneven weight.}\label{table:before_repartition}
    \end{center}
\end{table}

We repartition the problem, so that the workers have a weight closer to their ideal weight.

\begin{table}[H]
    \begin{center}
        \begin{tabular}{ | c | c | c | c | c | c | c | c | c | c | c | c | c | c | c | c | c | } 
            \hline
            worker \(p\) & \multicolumn{6}{c|}{\cellcolor{vs_lightgreen}0} & \multicolumn{4}{c|}{\cellcolor{vs_lightblue}1} & \multicolumn{3}{c|}{\cellcolor{vs_lightred}2} & \multicolumn{3}{c|}{\cellcolor{vs_lightplum}3}  \\
            \hline
            capacity \(c_p\) & \multicolumn{6}{c|}{\cellcolor{vs_lightgreen}2} & \multicolumn{4}{c|}{\cellcolor{vs_lightblue}2} & \multicolumn{3}{c|}{\cellcolor{vs_lightred}1} & \multicolumn{3}{c|}{\cellcolor{vs_lightplum}1}  \\
            \hline
            global id & \cellcolor{vs_lightgreen}0 & \cellcolor{vs_lightgreen}1 & \cellcolor{vs_lightgreen}2 & \cellcolor{vs_lightgreen}3 & \cellcolor{vs_lightgreen}4 & \cellcolor{vs_lightgreen}5 & \cellcolor{vs_lightblue}6 & \cellcolor{vs_lightblue}7 & \cellcolor{vs_lightblue}8 & \cellcolor{vs_lightblue}9 & \cellcolor{vs_lightred}10 & \cellcolor{vs_lightred}11 & \cellcolor{vs_lightred}12 & \cellcolor{vs_lightplum}13 & \cellcolor{vs_lightplum}14 & \cellcolor{vs_lightplum}15 \\ 
            \hline
            local id i & \cellcolor{vs_lightgreen}0 & \cellcolor{vs_lightgreen}1 & \cellcolor{vs_lightgreen}2 & \cellcolor{vs_lightgreen}3 & \cellcolor{vs_lightgreen}0 & \cellcolor{vs_lightgreen}1 & \cellcolor{vs_lightblue}2 & \cellcolor{vs_lightblue}3 & \cellcolor{vs_lightblue}0 & \cellcolor{vs_lightblue}1 & \cellcolor{vs_lightred}2 & \cellcolor{vs_lightred}3 & \cellcolor{vs_lightred}0 & \cellcolor{vs_lightplum}1 & \cellcolor{vs_lightplum}2 & \cellcolor{vs_lightplum}3 \\ 
            \hline
            weight \(w_i\) & \cellcolor{vs_lightgreen}1 & \cellcolor{vs_lightgreen}1 & \cellcolor{vs_lightgreen}1 & \cellcolor{vs_lightgreen}1 & \cellcolor{vs_lightgreen}2 & \cellcolor{vs_lightgreen}2 & \cellcolor{vs_lightblue}3 & \cellcolor{vs_lightblue}2 & \cellcolor{vs_lightblue}2 & \cellcolor{vs_lightblue}1 & \cellcolor{vs_lightred}2 & \cellcolor{vs_lightred}1 & \cellcolor{vs_lightred}1 & \cellcolor{vs_lightplum}1 & \cellcolor{vs_lightplum}2 & \cellcolor{vs_lightplum}1 \\ 
            \hline
            total weight \(w_p\) & \multicolumn{6}{c|}{\cellcolor{vs_lightgreen}8} & \multicolumn{4}{c|}{\cellcolor{vs_lightblue}8} & \multicolumn{3}{c|}{\cellcolor{vs_lightred}4} & \multicolumn{3}{c|}{\cellcolor{vs_lightplum}4} \\ 
            \hline
            ideal weight \(w_{ideal,p}\) & \multicolumn{6}{c|}{\cellcolor{vs_lightgreen}8} & \multicolumn{4}{c|}{\cellcolor{vs_lightblue}8} & \multicolumn{3}{c|}{\cellcolor{vs_lightred}4} & \multicolumn{3}{c|}{\cellcolor{vs_lightplum}4} \\ 
            \hline
        \end{tabular}
    
        \caption{Problem after repartition: The workers have a better workload distribution.}\label{table:after_repartition}
    \end{center}
\end{table}

This is the more general approach to repartitioning. Knowing our problem, we can simplify in two
ways. Tasks are elements, and workers are \acrshortpl{acr:GPU}. Firstly, since we do not work in
mixed systems, all workers have equal capacity. In typical \acrshort{acr:HPC} systems, nodes have
multiples of the same model of \acrshort{acr:GPU}. Since the program only executes on
\acrshortpl{acr:GPU}, all the workers will therefore be the same. See
Section~\ref{section:conclusion:future_work} for proposals of a solver that has both
\acrshort{acr:GPU} and \acrshort{acr:CPU} workers in order to fully utilise supercomputer nodes.
Such a system would necessitate the use of different capacities, since these nodes have many more
\acrshort{acr:CPU} cores than \acrshortpl{acr:GPU}, while each \acrshort{acr:GPU} is much faster. 

Secondly, each element will be given equal weight. This greatly simplifies the computing of total
weight within a \acrshort{acr:GPU}, since it becomes  directly related to the number of elements. It
also simplifies transfers between processes, as now only the number of elements in each process is
needed to compute which elements need to be sent or received. This assumes that each element has the
same computational complexity regardless of any factor, like its polynomial order. Of course, this
is not true. However, the computational cost of elements was not observed to vary significantly for
relatively low order polynomials. When the polynomial order is very different between elements, the
increased number of collocation points to compute and the increased memory needed to store the
solution start increasing the computation time for those elements. If this proves to be a
significant problem, Section~\ref{section:conclusion:future_work} discusses using weights for
elements, and a way to relate polynomial order to the weight. 

\section{Reconstruction}\label{section:load_balancing:reconstruction}

Now that we have a way to repartition work, the reconstruction of the mesh can begin. Each
\acrshort{acr:GPU} worker shares its number of elements with \(MPI\_Allgather\), so that every worker
knows how many elements each worker currently has. They can then calculate the global id of their
first and last element. Using the total number of elements in the mesh divided by the number of
workers, they can compute their new number of elements, and their new first and last global element
id. Any element they have that is out of this new range, they send. Knowing the new number of
elements per process, it is easy to compute to which process the elements need to be sent based on
their global element id. Any element missing from their new range, they need to receive. Again,
using the previous number of elements per process, it is easy to compute from which process these
elements should come. 

The knowledge of which elements to receive and send with which process is used to set up
\acrshort{acr:MPI} transfers. All the data is sent and received in a non-blocking way with
\(MPI\_Isend\) and \(MPI\_Irecv\), and once these transactions are completed the mesh can be
reconstructed in each process.

\subsection{Data transfer}\label{subsection:load_balancing:reconstruction:data_transfer}

The element objects array is allocated from the \acrshort{acr:CPU}, therefore elements can be copied
from the \acrshort{acr:GPU} to the \acrshort{acr:CPU} directly. The relevant data members are the
polynomial order of the elements, their Hilbert curve status, their rotation and their split level.
All other members are either not stored directly in the element structure and therefore cannot be
copied directly, or can be computed again when received. An \acrshort{acr:MPI} datatype is created
to be able to send and receive arrays of elements directly without copying that data into separate
arrays. Subsection~\ref{subsection:load_balancing:implementation:element_exchange} details this
process.

The solution data of an element is not so easy to transfer between processes. The solution arrays
are stored in \acrshort{acr:GPU} dynamic memory and the elements only hold a pointer to them. Being
allocated from the \acrshort{acr:GPU}, these arrays cannot be transferred to the \acrshort{acr:CPU}
directly. They also have a different size depending on the element's polynomial order. To solve
this, a buffer is allocated from the \acrshort{acr:CPU} on the \acrshort{acr:GPU}, and a kernel is
launched to copy each element's solution into this buffer on the \acrshort{acr:GPU}. To do this in
parallel, the buffer is of the maximum size of the solution, times the number of elements. This is
so elements can easily compute where to copy their data without race conditions. This uses more
memory than if the solution was packed, but then it would be harder for elements to find their data
on the receiving end, and to find where to write it on the sending end. 

This kernel allows us to fetch other data that is not readily available on the \acrshort{acr:CPU}.
Processes only store the mesh block assigned to them, with no information on elements, nodes, faces
or boundaries from other processes. Elements store the indices of their nodes, whereas the nodes
themselves are stored in an array of their own. These indices are meaningless to the receiving
process, as it has no idea what nodes those indices correspond to. The kernel fetching the solution
data from the \acrshort{acr:GPU} also copies the node values to an array, so that the four
coordinates of the corners of each element can be sent.

This is all the data that is needed to send the elements themselves from one \acrshort{acr:GPU} to
the other. Once it is received, it is stored using the inverse process. The nodes are checked for a
match among the existing nodes within the receiving \acrshort{acr:GPU}, otherwise new nodes are
appended to the node array. Then, elements need to be linked to their neighbours. 

The nodes themselves are not enough to derive the connectivity of an element. The number of faces on
a side of an element has no upper bound, so the data will need to be packed and offsets will need to
be computed. A first kernel retrieves the number of faces, and therefore neighbours, on each side of
elements to be sent. This information is used on both the sending and receiving sides to allocate
arrays that can fit the total number of neighbours, as well as compute offsets to where each element
has its neighbours in these arrays. Information to be fetched from neighbours and sent includes: the
neighbours' local indices, process, side, polynomial order, and the two nodes on the connecting
side. This information is used both to find the relevant neighbour if it is also in the receiving
process, and to create \acrshort{acr:MPI} boundaries if the neighbour is in another process.

On the subject of \acrshort{acr:MPI} boundaries, another data exchange must take place during load
balancing. Every process that has an \acrshort{acr:MPI} boundary with another process must send the
new local index and new process of each element making up that boundary. This is so the other
process knows to receive from another process if the element has been sent to a new process. This is
also necessary to send elements that are adjacent to an \acrshort{acr:MPI} boundary, as these
elements will have neighbours in another process whose local indices need to be updated.

\subsection{Connectivity}\label{subsection:load_balancing:reconstruction:connectivity}

Once all the data has been received, the mesh needs to be reassembled. Faces and boundary elements
that link to elements that have been sent are removed. Faces around received elements are created,
or reused if the element happens to have been the destination of an \acrshort{acr:MPI} interface.
New boundary elements, also called ghost elements because they are not part of the domain, are
created around received elements, and as a replacement for sent elements. Elements and faces that
are kept are moved to new indices, using a similar prefix sum to the one used in
Subsection~\ref{subsection:adaptive_mesh_refinement:implementation:moving_elements}. All references
to these faces and elements are updated.

Figures~\ref{fig:lb_before} and~\ref{fig:lb_after} illustrate an example of the whole load balancing
process, where two processes initially have an unbalanced number of elements because of a prior
refinement. The domain spans \(x, y \in [0, 1]\) and the elements making up that domain are split
between two \acrshortpl{acr:GPU}. 

\begin{figure}[H]
    \centering
    \subfloat[Process 0]
    {\includesvg[width=0.3\textwidth]{Chapter_load_balancing/media/mesh_0_before0_lb}\label{fig:lb_before_0}}
    \qquad
    \subfloat[Process 1]
    {\includesvg[width=0.3\textwidth]{Chapter_load_balancing/media/mesh_1_before0_lb_legend}\label{fig:lb_before_1}}
    \caption{Mesh before load balancing: The two blocks have different numbers of elements.}\label{fig:lb_before}
\end{figure}

\begin{figure}[H]
    \centering
    \subfloat[Process 0]
    {\includesvg[width=0.3\textwidth]{Chapter_load_balancing/media/mesh_0_after0_lb}\label{fig:lb_after_0}}
    \qquad
    \subfloat[Process 1]
    {\includesvg[width=0.6\textwidth]{Chapter_load_balancing/media/mesh_1_after0_lb_legend}\label{fig:lb_after_1}}
    \caption{Mesh after load balancing: The two blocks have equal numbers of elements.}\label{fig:lb_after}
\end{figure}

\section{Load Balancing Criteria}\label{section:load_balancing:criteria}

Dynamic load balancing is a costly process, especially when using \acrshortpl{acr:GPU}. Transfers
between \acrshortpl{acr:GPU} are expensive, as is reallocating memory for arrays that change size.
Load balancing at every occasion would needlessly waste resources than could be used to solve the
program. A balance has to be established between having a good quality mesh for a longer part of the
computation against load balancing less often and saving the load balancing processing time.

Two approaches are studied in this work to alleviate this problem. The first approach is to load
balance the mesh at a regular interval. If the mesh is not refined after each \acrshort{acr:AMR}
step, but every few \acrshort{acr:AMR} steps, computation time can be saved on the load balancing
routine. On the other hand, the mesh may be unbalanced between these steps. If a particularly large
number of elements are refined at a time, a significant load imbalance can persist until the next
load balancing step.

The second approach is to set an acceptable load imbalance, under which the mesh will not be load
balanced. After refining, if the load imbalance \(L\) is below that threshold, the mesh will not be
load balanced. This means that the mesh will only be load balanced when it is really needed. The
disadvantage is that the load imbalance could stay slightly below that threshold indefinitely,
leaving the program with a slightly imbalanced mesh for large parts of its runtime.

The two approaches are compared in Section~\ref{section:results:load_balancing_performance}.

\section{Implementation}\label{section:load_balancing:implementation}

Dynamic load balancing presents significant challenges when \acrshortpl{acr:GPU} are used. Mesh data
that resides on the \acrshort{acr:GPU} is not readily accessible by the \acrshort{acr:CPU} to be
transferred from one \acrshort{acr:GPU}to another, and as much of the algorithm as possible should
run on the \acrshort{acr:GPU} in parallel. Also, reconstructing the mesh and the connectivity
between blocks is difficult when no worker has a global view of the mesh. 

\subsection{Element exchange}\label{subsection:load_balancing:implementation:element_exchange}

Computing which elements to exchange from one \acrshort{acr:GPU} to another is fairly
straightforward. The workload levelling from Section~\ref{section:load_balancing:workload_leveling}
informs each worker of which elements it should send to which other worker, and which elements it
should receive from which other worker. 

As mentioned previously, the element solution is stored in dynamic \acrshort{acr:GPU} memory, and
cannot be copied directly to the \acrshort{acr:CPU}. A kernel is launched to copy that data to an
array which can then be copied to the \acrshort{acr:CPU}. Algorithm~\ref{alg:get_transfer_solution}
shows how that data is packed in the solution array to be sent between workers. The values of the
four nodes of each element are also stored, as well as the number of neighbours on each side. The
data is aligned to the maximum polynomial order used by the program, so that elements can store
their solution in parallel without knowledge of other elements' polynomial order. This wastes space
as most elements do not use the entire space they are assigned to in the transfer arrays. Since this
avoids computing an offset array to indicate where each element's solution should be placed if the
data was packed, this tradeoff is accepted.

\begin{algorithm}[H]
    \begin{cuda}
        __global__
        auto get_transfer_solution(size_t n_elements, const Element2D_t* elements, 
                int maximum_N, const Vec2<deviceFloat>* nodes, deviceFloat* solution, 
                size_t* n_neighbours, deviceFloat* element_nodes) -> void {

            const int index = blockIdx.x * blockDim.x + threadIdx.x;
            const int stride = blockDim.x * gridDim.x;

            for (size_t i = index; i < n_elements; i += stride) {
                const size_t p_offset =  3 * i      * std::pow(maximum_N + 1, 2);
                const size_t u_offset = (3 * i + 1) * std::pow(maximum_N + 1, 2);
                const size_t v_offset = (3 * i + 2) * std::pow(maximum_N + 1, 2);
                const size_t neighbours_offset = 4 * i;
                const size_t nodes_offset = 8 * i;

                const Element2D_t& element = elements[i];

                n_neighbours[neighbours_offset]     = element.faces_[0].size();
                n_neighbours[neighbours_offset + 1] = element.faces_[1].size();
                n_neighbours[neighbours_offset + 2] = element.faces_[2].size();
                n_neighbours[neighbours_offset + 3] = element.faces_[3].size();
                element_nodes[nodes_offset]     = nodes[element.nodes_[0]].x();
                element_nodes[nodes_offset + 1] = nodes[element.nodes_[0]].y();
                element_nodes[nodes_offset + 2] = nodes[element.nodes_[1]].x();
                element_nodes[nodes_offset + 3] = nodes[element.nodes_[1]].y();
                element_nodes[nodes_offset + 4] = nodes[element.nodes_[2]].x();
                element_nodes[nodes_offset + 5] = nodes[element.nodes_[2]].y();
                element_nodes[nodes_offset + 6] = nodes[element.nodes_[3]].x();
                element_nodes[nodes_offset + 7] = nodes[element.nodes_[3]].y();

                for (int j = 0; j < std::pow(element.N_ + 1, 2); ++j) {
                    solution[p_offset + j] = element.p_[j];
                    solution[u_offset + j] = element.u_[j];
                    solution[v_offset + j] = element.v_[j];
                }
            }
        }\end{cuda}
\caption{\textbf{get\_transfer\_solution:} The solution data of elements is stored in parallel in an array.}\label{alg:get_transfer_solution}
\end{algorithm}

Elements can have an arbitrary number of neighbours, therefore neighbour data cannot be staggered in
the same way as solution data. This is why we need to transfer the number of neighbours on each side
of elements, so as to generate the neighbour information arrays with the correct size, and to
generate offset arrays so each element stores its neighbour data in the correct memory location. The
neighbour data fetch kernel is much more complicated than Algorithm~\ref{alg:get_transfer_solution},
but operates in a similar manner. The main difference is that neighbour data is not readily
available if a neighbour is a boundary element. In that case the different boundary condition and
\acrshort{acr:MPI} interface arrays are searched to find which one the boundary element belongs to,
and to find the required information that way. This is because boundary elements that are part of an
\acrshort{acr:MPI} interface must present the local index and process of the element on the other
side of the interface, and boundary condition boundary elements must encode which kind of boundary
condition they are.

Elements themselves are copied directly from the \acrshort{acr:GPU} to the \acrshort{acr:CPU} since
they are stored in \acrshort{acr:CPU}-allocated \acrshort{acr:CUDA} \acrshort{acr:GPU} memory. Using
a created \acrshort{acr:MPI} datatype, arrays of elements objects can be directly sent through
\acrshort{acr:MPI}. Algorithm~\ref{alg:mpi_datatype} shows how the datatype is created, and which
data members from the element object are sent.

\begin{algorithm}[H]
    \begin{cuda}
        Element2D_t::Datatype::Datatype() {
            constexpr int n = 4;
            constexpr std::array<int, n> lengths {
                1, 
                1, 
                1, 
                1
            };
            constexpr std::array<MPI_Aint, n> displacements {
                offsetof(Element2D_t, N_), 
                offsetof(Element2D_t, status_), 
                offsetof(Element2D_t, rotation_), 
                offsetof(Element2D_t, split_level_)
            };
            const std::array<MPI_Datatype, n> types {
                MPI_INT, 
                MPI_INT, 
                MPI_INT, 
                MPI_INT
            };

            MPI_Datatype tmp_type;
            MPI_Type_create_struct(n, lengths.data(), 
                displacements.data(), types.data(), &tmp_type);
            // We resize the datatype to be able to send arrays of elements
            MPI_Type_create_resized(tmp_type, 0, sizeof(Element2D_t), &datatype_);
            MPI_Type_commit(&datatype_);
        }\end{cuda}
\caption{\textbf{MPI\_datatype:} The solution data of elements is stored in parallel in an array.}\label{alg:mpi_datatype}
\end{algorithm}

\subsection{Mesh reconstruction}\label{subsection:load_balancing:implementation:reconstruction}

Once all elements to be transferred and their neighbour information have been sent and received, the
mesh must be reconstructed. This is the more difficult part of the process, as many edge cases
exist. An example operation is the \textbf{find\_faces\_to\_delete} kernel, showcased in
Algorithm~\ref{alg:find_faces_to_delete}, which marks faces without any remaining domain elements as
neighbours for deletion.

\begin{algorithm}[H]
    \begin{cuda}
        __global__
        auto find_faces_to_delete(size_t n_faces, size_t n_domain_elements, 
                size_t n_elements_send_left, size_t n_elements_send_right, 
                const Face2D_t* faces, bool* faces_to_delete) -> void {

            const int index = blockIdx.x * blockDim.x + threadIdx.x;
            const int stride = blockDim.x * gridDim.x;

            for (size_t i = index; i < n_faces; i += stride) {
                const Face2D_t& face = faces[i];
                const std::array<bool, 2> elements_leaving {
                    face.elements_[0] < n_elements_send_left 
                        || (face.elements_[0] >= n_domain_elements - n_elements_send_right 
                            && face.elements_[0] < n_domain_elements),
                    face.elements_[1] < n_elements_send_left 
                        || (face.elements_[1] >= n_domain_elements - n_elements_send_right 
                            && face.elements_[1] < n_domain_elements)
                };
                const std::array<bool, 2> boundary_elements {
                    face.elements_[0] >= n_domain_elements,
                    face.elements_[1] >= n_domain_elements
                };

                faces_to_delete[i] = elements_leaving[0] && elements_leaving[1] 
                                  || elements_leaving[0] && boundary_elements[1] 
                                  || elements_leaving[1] && boundary_elements[0];
            }
        }\end{cuda}
\caption{\textbf{find\_faces\_to\_delete:} Faces with no remaining domain neighbour elements are marked for deletion.}\label{alg:find_faces_to_delete}
\end{algorithm}

This algorithm provides part of the foundation of the part of load balancing concerning faces, but
is only the start. Faces need to be moved to a new index to remove the gaps from deleted faces. We
then need to update the face indices in all elements, and resize the elements' neighbour faces
arrays if some of the faces have been deleted. New faces have to be added to the face array to
connect the new received elements to the mesh.

Ghost elements can be marked for deletion if all the faces connecting them to the domain are to be
deleted, except in two special cases. Ghost elements that are part of an \acrshort{acr:MPI}
interface need to be deleted if the element on the other side of the interface is sent to the
process containing the boundary element. Algorithm~\ref{alg:find_mpi_interface_elements_to_delete}
details a kernel that is launched specially to deal with this edge case. Also, boundary elements can
be marked for deletion because no domain element connects them anymore, but some received elements
could connect to them. Another kernel, shown in
Algorithm~\ref{alg:find_mpi_interface_elements_to_keep}, is launched to deal with this case.

\begin{algorithm}[H]
    \begin{cuda}
        __global__
        auto find_mpi_interface_elements_to_delete(size_t n_mpi_interface_elements, 
                size_t n_domain_elements, int rank, 
                const size_t* mpi_interfaces_destination, 
                const int* mpi_interfaces_new_process_incoming, 
                bool* boundary_elements_to_delete) -> void {

            const int index = blockIdx.x * blockDim.x + threadIdx.x;
            const int stride = blockDim.x * gridDim.x;

            for (size_t i = index; i < n_mpi_interface_elements; i += stride) {
                if (mpi_interfaces_new_process_incoming[i] == rank) {
                    boundary_elements_to_delete[mpi_interfaces_destination[i] 
                                              - n_domain_elements] = true;
                }
            }
        }\end{cuda}
\caption{\textbf{find\_mpi\_interface\_elements\_to\_delete:} \Acrshort{acr:MPI} interface elements should be deleted if the element on the other side of the interface is moved to the same process.}\label{alg:find_mpi_interface_elements_to_delete}
\end{algorithm}

\begin{algorithm}[H]
    \begin{cuda}
        __global__
        auto find_mpi_interface_elements_to_keep(size_t n_mpi_destinations, 
                size_t n_neighbours, int rank, size_t n_domain_elements, 
                const int* neighbour_procs, const size_t* neighbour_indices, 
                const size_t* neighbour_sides, const int* mpi_destination_procs, 
                const size_t* mpi_destination_local_indices, 
                const size_t* mpi_destination_sides, 
                const size_t* mpi_interfaces_destination, 
                bool* boundary_elements_to_delete) -> void {

            const int index = blockIdx.x * blockDim.x + threadIdx.x;
            const int stride = blockDim.x * gridDim.x;

            for (size_t i = index; i < n_mpi_destinations; i += stride) {
                const int mpi_proc = mpi_destination_procs[i];

                // The element is marked for deletion because either all linking elements are sent
                // Maybe we received an element that links to it, then we must keep it
                if  (mpi_proc != rank 
                  && boundary_elements_to_delete[mpi_interfaces_destination[i]-n_domain_elements]) {
                    const size_t mpi_index = mpi_destination_local_indices[i];
                    const size_t mpi_side = mpi_destination_sides[i];
                    for (size_t j = 0; j < n_neighbours; ++j) {
                        const int neighbour_proc = neighbour_procs[j];
                        const size_t neighbour_index = neighbour_indices[j];
                        const size_t neighbour_side = neighbour_sides[j];

                        if  (mpi_proc  == neighbour_proc 
                          && mpi_index == neighbour_index 
                          && mpi_side  == neighbour_side) {
                            boundary_elements_to_delete[mpi_interfaces_destination[i] 
                                                      - n_domain_elements] = false; 
                            break;
                        }
                    }
                }
            }
        }\end{cuda}
\caption{\textbf{find\_mpi\_interface\_elements\_to\_keep:} \Acrshort{acr:MPI} interface elements should be kept if a received element now connects to it.}\label{alg:find_mpi_interface_elements_to_keep}
\end{algorithm}

This example is presented to show that the apparent simplicity of
Algorithm~\ref{alg:find_faces_to_delete} is complicated when all the edge cases of a dynamically
changing mesh are factored in. Adding to the complexity is the fact that the \acrshort{acr:GPU}
workers only have knowledge of their own mesh block, as well as the neighbour information of the
received elements. The different computations are also executed in parallel on the
\acrshort{acr:GPU}, since each \acrshort{acr:GPU} is paired with a single \acrshort{acr:CPU} which
would heavily bottleneck the process if it was used for all calculations.

Many more operations remain, such as moving elements that are not deleted to their new position in
the array, adding received elements, adding boundary elements around received elements, and updating
the element indices in all faces. The \acrshort{acr:MPI} interfaces must also be rebuilt and ordered
since elements may have moved from one process to another. The methods used are similar to those
used for faces, and those seen in Section~\ref{section:adaptive_mesh_refinement:implementation}. 
