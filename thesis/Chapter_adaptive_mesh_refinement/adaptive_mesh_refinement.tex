\chapter{Adaptive Mesh Refinement} \label{chapter:adaptive_mesh_refinement} 
% Something about move semantics
% No coarsening
% Adaptivity triggers
% Mortar here

Computers constantly increase in power, thanks to incremental progress made on known processes and
new architectures such as that described in chapter~\ref{chapter:graphics_processing_units}.
However, processing power and memory is still limited and the size of problems studied has
increased in step with the available ressources. It is still necessary to carefully manage those
limited ressources in order to maximise the efficiency of simulations. Some flow regions may be more
interesting or harder to compute, benefiting from an increase in resolution. On the other hand, some
flow regions may have less happening in them or be easier to compute, and a decrease in resolution
may be acceptable.

\begin{figure}[H]
	\centering
	\includegraphics[width=0.4\textwidth]{Chapter_adaptive_mesh_refinement/media/mesh_refinement}
	\caption{Adaptive mesh refinement: The elements have split near the wave, where the solution is steeper}
	\label{fig:mesh-refinement}
\end{figure}

It is possible to increase the number of elements and/or the polynomial order of an entire mesh
before solving the problem. This increases resolution in important areas of the flow, but also
increases resolution everywhere else in the domain, where the increased computation cost provides no
benefit. It is sometimes possible to predict where to refine before solving the problem, such as
around static shock waves in predictable locations. In these cases, the mesh can be refined in those
areas before computation has started. However, it is not always possible to know these areas
beforehand, or these areas may move as time advances if the problem is transient. The error may also
be higher in unforeseen areas that are not apparent.

Adaptive mesh refinement is the process of mesh resolution as the computation goes, where the effect
of that increase in resolution is most needed. To find out where to refine, the solution error must
be estimated, and a refinement method must be chosen. The error can be estimated by extrapolating
the value of the next mode, and the slope of the last few nodes can guide the choice of the
refinement method. The two refinement methods studied here are h-refinement and p-refinement,
increasing the number of elements and the polynomial order, respectively. 

This whole process must be executed in parallel and with as much as the work as possible executed on
the GPU. GPUs are more efficient at working with fixed workloads where all threads of a block
execute the same instruction. Refining the mesh moves memory around and can introduce additional
branching if the elements have different polynomial orders or non-conforming interfaces. The
adaptivity process itself is also hard to implement on GPUs, as elements must either move, change
their polynomial order or split into multiple elements in parallel. If the different threads are not
perfectly coordinated, they could do these operations on the same destination memory location,
creating race conditions.

Once the mesh has been refined, the element boundaries can become geometrically or functionally
non-conforming. To compute fluxes between the elements, we use the mortar element method. Mortar, in
the form of faces, is added between the elements, and the boundary solution is projected from the
elements to the face's own collocation points. 

When solving problems in parallel, the mesh will be split into blocks, each assigned to a process
and its GPU. As the mesh is refined, it is possible that the blocks are refined unequally. This can
lead to a load imbalance between the different GPUs. As the different GPUs need to synchronise at
each timestep, lightly-loaded GPUs will always be waiting after heavily-loaded GPUs. The computation
time will therefore be driven by the most heavily-loaded GPU, and the speedup incurred by
parallelizing the program will be reduced. To improve this side effect of mesh refinement, a dynamic
load balancing algorithm will be implemented in chapter~\ref{chapter:load_balancing}.

\section{Strategies} \label{section:adaptive_mesh_refinement:adaptivity_strategies}

\subsection{p-adaptivity} \label{section:adaptive_mesh_refinement:adaptivity_strategies:p-adaptivity}

\begin{figure}[H]
	\centering
	\includesvg[width=0.6\textwidth]{Chapter_adaptive_mesh_refinement/media/p-adaptivity_N4_N6}
	\caption{2D p-adaptivity: The element's polynomial order is increased from 4 to 6}
	\label{fig:p-adaptivity}
\end{figure}

The first refinement strategy is p-adaptivity. When refining this way, elements increase their
polynomial order to increase their resolution. The lower-order solution is projected to the
higher-order collocation points. In this work, the polynomial order in increased in steps of 2, and
the polynomial order stays the same in the x and y directions. 

\subsection{h-adaptivity} \label{section:adaptive_mesh_refinement:adaptivity_strategies:h-adaptivity}

\begin{figure}[H]
	\centering
	\includesvg[width=0.6\textwidth]{Chapter_adaptive_mesh_refinement/media/h-adaptivity_N4}
	\caption{2D h-adaptivity: The element splits into 4 elements}
	\label{fig:h-adaptivity}
\end{figure}

The second refinement strategy is h-adaptivity. h-adaptivity splits single elements into several
elements occupying the same space. In this work we exclusively deal with quadrilaterals, and these
elements split in 4 smaller elements when h-refining. The solution is projected from the initial big
element to each of the 4 offspring elements.

\subsection{hp-adaptivity} \label{section:adaptive_mesh_refinement:adaptivity_strategies:hp-adaptivity}

In order to maximise computation efficiency, both p-adaptivity and h-adaptivity are used together.
An hp-adaptive program uses either p-adaptivity or h-adaptivity on an element-by-element basis,
depending on which is expected to reduce error the most. The choice between the two methods is
detailed in section~\ref{section:adaptive_mesh_refinement:refinement_criteria}.

\begin{figure}[H]
	\centering
	\includesvg[width=0.6\textwidth]{Chapter_adaptive_mesh_refinement/media/hp-adaptivity_N4_N6}
	\caption{2D hp-adaptivity: Elements refining create non-conforming interfaces}
	\label{fig:hp-adaptivity}
\end{figure}

Once the mesh has been refined, it is possible that the interfaces between elements become
non-conforming. Recall from chapter~\ref{chapter:spectral_element_method} that fluxes are computed
between the elements from the extrapolated values of the solution on collocation points matching the
polynomial order of the elements. These would be the tips of the thin black lines in the figure
above. This works directly if two neighbouring elements have the same polynomial order and they
completely share an edge. However, after p-adaptivity interfaces can become functionally
non-conforming, as seen with the rightmost blue line in the figure above. The nodes won't match
anymore since one element has more points than the other. After h-adapting, interfaces can become
geometrically non-conforming, as seen with the topmost blue line in the figure above. The nodes do
not match because one edge is shorter than the other. Finally, interfaces can be both geometrically
and functionally non-conforming, as seen with the bottom blue line in the figure above. We will have
to find a way to connect those elements in a way that retains the spectral convergence of the
method.

\begin{figure}[H]
	\centering
	\includegraphics[width=0.4\textwidth]{Chapter_adaptive_mesh_refinement/media/load_imbalance}
	\caption{Load imbalance: The elements have split unequally in the two worker GPUs, one having a higher computational load}
	\label{fig:load-imbalance}
\end{figure}

\section{Error Estimation} \label{section:adaptive_mesh_refinement:error_estimation}

\section{Refinement Criteria} \label{section:adaptive_mesh_refinement:refinement_criteria}

\section{Mortar Element Method} \label{section:adaptive_mesh_refinement:mortar_element_method}

\section{Implementation} \label{section:adaptive_mesh_refinement:implementation}

As detailed in chapter~\ref{chapter:graphics_processing_units}, the grid is stored on the GPU as a
flat array of elements, each element having pointers to its solution arrays, stored in GPU dynamic
memory. This ensures the elements have a fixed size regardless of their polynomial order.