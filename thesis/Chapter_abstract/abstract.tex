\thispagestyle{plain} % stop the headers being added in

\begin{center}
	\vspace*{0.5cm} % vertical gap. *" makes sure Latex does not ignore the command. 
	\phantomsection\addcontentsline{toc}{chapter}{Abstract}
	{ \Large
		\textbf{A Graphics Processing Unit based \\ 
			Discontinuous Galerkin Wave Equation Solver \\
			with hp-adaptivity and Load Balancing \\
		}
	}
	\vspace{0.4cm}
	\large

	by \\
	\vspace{0.4cm}
	\textbf{Guillaume Tousignant}
	
	\vspace{0.9cm}
	\textbf{Abstract}
	
\end{center}

In order to simulate complex fluid flows, high-order methods can be used to obtain very fine results. However, these methods are computationally expensive, 

and care should be taken to optimise their execution time. \textit{Graphics Processing Units (GPUs)} are a relatively new architecture in the domain of 

scientific computing, leveraging massive parallelism at the expense of reduced flexibility. To achieve the resolution of high-order methods with the 

throughput of GPUs, we use the \textit{discontinuous Galerkin spectral element method (DG-SEM)} coupled with parallel \textit{adaptive mesh refinement (AMR)}

to solve the two-dimensional wave equation. The \textit{discontinuous Galerkin spectral element method (DG-SEM)} splits the domain in elements, within which

the solution is represented as a weighted series of orthogonal polynomials, the \textit{Legendre polynomials} in this case. To insure no ressources are 

wasted, the \textit{adaptive mesh refinement (AMR)} aims to increase the resolution in regions of interest, via two mechanisms: \textit{h-refinement}, where

elements are split in multiple smaller ones, and \textit{p-refinement}, where the polynomial order within an element is increased. In order to retain the 

fast convergence high-order methods are known for, the \textit{mortar element method} is used to resolve the fluxes between geometrically or order(???) 

non-conforming elements.



Scientific or engineering simulations of complex fluid flows, \textit{e.g.}, turbulent flow, often resort to high-order methods to obtain high resolutions. However, a large-scale, time-dependent, long-time simulation can be extremely  computationally expensive. To achieve high resolution while maximizing the computational savings, we combine a high-order method -- the \textit{discontinuous Galerkin spectral element method (DG-SEM)}, with parallel \textit{adaptive mesh refinement and coarsening (AMR)} techniques and apply it to a two-dimensional wave equation solver. DG-SEM discretizes solution functions as weighted polynomial series. In this work, \textit{Legendre polynomials} are chosen. With higher-order method and AMR techniques, a computational cost-efficient solver is formed. 

Two types of refinements are invoked: \textit{h-refinement}, where elements are split or merged, and \textit{p-refinement}, where polynomial orders can be increased or decreased. To retain the spectral convergence on the \textit{non-conforming} element interfaces caused by the hp-refinement, the \textit{mortar element method} is adopted. 

\textit{A hash table AMR} technique is developed for the AMR data encoding and storing. It can be built independently on distributed memory systems. It provides high control of the mesh resolution and efficient data management operations. Results using this approach on the adaptive wave equation solver confirm that its memory usage remains low on up to $16,384$ processors for a problem with over a million elements and 150 million degrees of freedom.

Dynamic load imbalance is incurred by the adaptivity of the program, which degrades the performance of the supercomputers. A \textit{space-filling curve (SFC) based} repartitioning algorithm is implemented in this work. The algorithm is designed to execute quickly in parallel. Its low memory overhead is beneficial to distributed memory systems. Additionally, the high-quality repartitioning results successfully reduce the dynamic workload imbalance among the computational processors. The scalability of the load balancing algorithm is demonstrated on two different high-performance computing systems with up to $16,384$ processors. The maximum memory scaling is up to 4,096 processors and no considerable memory growth is observed beyond the maximum scaling. High load balancing quality is demonstrated. 

% -------------------------------------------------
% add sth about the scaling performance 
% -------------------------------------------------

Using the hash table AMR and SFC-based repartitioning algorithm, we obtain speedup factors up to $8.46$ over a range of processor numbers from $32$ to $2048$, which, in the long run, can reduce week-long computational wait-times to a matter of days. 

\textbf{Keywords}: Spectral element method, adaptive mesh refinement, space-filling curves, Hilbert curve, dynamic load balancing, large-scale scientific computing.

 