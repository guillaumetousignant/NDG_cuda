\chapter{Discontinuous Galerkin Spectral Element Method}\label{chapter:spectral_element_method}

In this chapter we present the methodology of the \textit{\acrfull{acr:DG-SEM}} and detail its
application to solving the 2D wave equation. This method is part of the broader class of spectral
methods, applied within local elements as in finite-element methods. This method exhibits the
exponential convergence of spectral methods, while adding the ability to model difficult geometries
of finite-element methods. The method is described in~\cite{Kopriva2009}, along with efficient
computer programming implementation strategies. The main model problem showcased throughout this
work depicts a diagonal wave moving through a square domain.

\section{Spectral Approximation}\label{section:spectral_element_method:spectral_approximation}

Spectral methods, as described by Gottlieb and Orszag~\cite{Gottlieb1977}, model functions as sums
of weighted orthogonal functions, often polynomials. Let us denote \(\phi_n(x)\) as the polynomial
of degree \(n\), and \(a_n\) as the weight of said polynomial. The weights make up the spectrum of
the solution.

\begin{equation} \label{equ:infinite_sum}
    \begin{split}
        f(x) & = \sum_{n = 0}^{\infty }a_n \phi_n(x)
    \end{split}
\end{equation}

Since it is impractical to sum an infinite number of polynomials on a computer, the sum is truncated
to a polynomial order \(N\). This becomes the polynomial order of the approximation. The truncated
part becomes \(\tau \), the truncation error.

\begin{equation} \label{equ:truncated_sum}
    \begin{split}
        f(x) & = \sum_{n = 0}^{\infty }a_n \phi_n(x) \\
        & = \sum_{n = 0}^{N}a_n \phi_n(x) + \sum_{n = N + 1}^{\infty }a_n \phi_n(x) \\
        & = \sum_{n = 0}^{N}a_n \phi_n(x) + \tau \\
        & \approx \sum_{n = 0}^{N}a_n \phi_n(x)
    \end{split}
\end{equation}

Since we discard part of the spectrum, it is important that the retained polynomial terms capture
the essential parts of the solution. We therefore want the weights to decay as fast as possible.
This will be a characteristic of the polynomials we choose. For example, Fourier series, Legendre
polynomials and Chebyshev polynomials have been proven~\cite{Kopriva2009} to have exponentially
decaying coefficients for smooth functions \(f(x)\), giving them spectral accuracy.

\subsection{Basis functions}\label{subsection:spectral_element_method:spectral_approximation:basis_functions}

Spectral methods exploit the orthogonality property of sets of functions. For orthogonal
functions in the domain \([a, b]\), we have:

\begin{equation} \label{equ:orthogonality}
    \int_{a}^{b}\phi_i(x) \phi_j(x)dx = C_i \delta_{i j}
\end{equation}

\noindent
with \(C_i\) being a constant, and \(\delta_{i j}\) being the Kronecker delta, defined as such:

\begin{equation} \label{equ:kronecker}
    \delta _{i j} = \left \{ \begin{matrix}
                    1, & \textrm{if} \quad i = j,\\ 
                    0, & \textrm{if} \quad i \neq j.
                    \end{matrix} \right.
\end{equation}

The inner product of two functions \(f(x)\) and \(g(x)\) continuous in
\(\left[ a, b \right]\), is:

\begin{equation}
    \left( f, g \right) = \int_{a}^{b} f(x) g(x) dx.
\end{equation}

\noindent
We can therefore rewrite Equation~\ref{equ:orthogonality} in inner product form:

\begin{equation}
    \left( \phi_i, \phi_j \right) = \int_{a}^{b} \phi_i(x) \phi_j(x) dx = C_i \delta_{i j}.
\end{equation}

Some sets of functions are only orthogonal in the context of integration with a weighting function \(w\):

\begin{equation}
    \left( \phi_i, \phi_j \right) = \int_a^b \phi_i(x) \phi_j(x) w(x) dx = B_{i} \delta_{i j},
\end{equation}

\noindent
where \(B_i\) is a constant.

Fourier series can be used for periodic problems. As for non-periodic problems, Legendre polynomials
and Chebyshev polynomials are more practical. Legendre polynomials have a weighting function of
\(w(x) = 1\), which simplifies computations. We will therefore use the Legendre polynomials.

\begin{figure}[H]
    \centering
    \includesvg[width=0.9\textwidth]{Chapter_spectral_element_method/media/polynomials}
    \caption{Legendre polynomials: The first six Legendre polynomials.}\label{fig:polynomials}
\end{figure}

The Legendre polynomials, illustrated in Figure~\ref{fig:polynomials}, were discovered by
Adrien-Marie Legendre in 1782. Using their associated weights \(w(x) = 1\) and the interval \(\left[
-1, 1 \right]\), the polynomials are orthogonal. The Legendre polynomials \(L_k \left( x \right)\)
of degree \(k\) therefore have the property:

\begin{equation}
    \int_{-1}^{1}L_{k_1}(x) L_{k_2}(x) dx = 0, \quad if \: \: k_1 \neq k_2.
\end{equation}

The Legendre polynomials can be generated using a three-term recursive formula. Knowing that the
first two polynomials are \(L_0 \left( x \right) = 1\) and \(L_1 \left( x \right) = x\), all
subsequent polynomials can be generated from the following formula.

\begin{equation} \label{equ:three_terms}
    L_{k + 1}(x) = \frac{2k + 1}{k + 1}xL_k(x) - \frac{k}{k + 1}L_{k - 1}(x)
\end{equation}

These polynomials will help us compute integrals using Gauss quadrature. For an interval \(\left[
-1, 1 \right]\), the Gauss quadrature formula is:

\begin{equation}
    \int_{-1}^{1}f(x)dx \approx \sum_{i = 0}^{N}w_i f(x_i).
\end{equation}

The points \(x_i\) used for the quadrature are the Gauss quadrature points, or collocation points.
Using the roots of the (N + 1)\textsuperscript{th} Legendre polynomial, the quadrature is exact for
polynomials of degree \(\leq 2 N + 1\). This is the \textit{Gauss-Legendre quadrature rule}. We use
the roots of the (N + 1)\textsuperscript{th} Legendre polynomial to get the points \(x_i\) and
weights \(w_i\).

\begin{gather}
    x_i = roots \: \: of \: \: L_{N + 1}(x), \quad i = 0, \ldots, N \\
    w_i = \frac{2}{(1-x_i^2) {\left[ L'_{N + 1}(x_i) \right]}^2}
\end{gather}

\subsection{Polynomial interpolation}\label{subsection:spectral_element_method:spectral_approximation:polynomial_interpolation}

Polynomial interpolation fits data to a polynomial passing through known points. The polynomial has
an order equal to the number of points minus one. In this work we use Lagrange integrating
polynomials \(l_j\) of degree N.

\begin{equation}
    l_j(x) = \prod_{\substack{i = 0 \\ i \neq j}}^{N}\frac{x- x_i}{x_j - x_i}
\end{equation}

At each Gauss-Legendre collocation point \(x_i\) only one of the integrating polynomials has the
value 1, the others having a value of 0. This mimics the Kronecker delta \(\delta_{i j}\).

\begin{equation}
    l_j(x_i) = \delta_{i j} = \left \{\begin{matrix}
    1, \quad i = j\\ 
    0, \quad i \neq j
    \end{matrix}\right.
\end{equation}

Figure~\ref{fig:interpolants} displays the interpolating polynomials of degree five:

\begin{figure}[H]
    \centering
    \includesvg[width=0.9\textwidth]{Chapter_spectral_element_method/media/interpolants}
    \caption{Polynomial interpolation: The Lagrange interpolating polynomials of degree five.}\label{fig:interpolants}
\end{figure}

With this, we can interpolate a function \(p_N(x)\) of degree N\@:

\begin{equation}
    p_N(x) = \sum_{j = 0}^{N}p(x_j)l_j(x).
\end{equation}

We can also modify the Lagrange interpolation to the barycentric form.

\begin{gather}
    p_N(x) = \psi(x)\sum_{j = 0}^{N}p(x_j)\frac{w_j}{x - x_j} \\
    \psi(x) = \prod_{i = 0}^{N}\left ( x - x_i \right ) \\
    w_j = \frac{1}{\prod_{\genfrac{}{}{0pt}{2}{i = 0}{i \neq j}}^{N}(x_j - x_i)}
\end{gather}

\noindent
We retain the same property as for the initial form:

\begin{equation}
    \psi(x)\sum_{j = 0}^{N}\frac{w_j}{x - x_j} = 1.
\end{equation}

We can then rewrite the complete Lagrange interpolation in barycentric form. By pre-computing the
barycentric weights \(w_j\), we can compute the interpolated value at any point \(x\) using only the
known values at the collocation points, without computing the interpolating polynomials. 

\begin{equation}
    p_N(x) = \frac{\sum_{j = 0}^{N} p(x_j)\frac{w_j}{x - x_j}}{\sum_{j = 0}^{N}\frac{w_j}{x - x_j}}
\end{equation}

\section{The Wave Equation Model}\label{section:spectral_element_method:equation}

We want to solve the 2D wave equation:

\begin{gather}
    \frac{\partial^2p}{\partial t^2} - c^2(p_{xx} + p_{yy}) = 0 \\
    u_t = - p_x \\
    v_t = -p_y
\end{gather}

\noindent
with \(p\) being the pressure, \(u\) and \(v\) being the two components of the velocity, and \(c\)
being the sound speed. The three equations can be combined into one.

\begin{equation} \label{equ:2d_wave}
    \frac{\partial^2p}{\partial t^2} + c^2 \left( {\left( u_x \right)}_t + {\left( v_y \right)}_t \right) = 0
\end{equation}

We then integrate once with respect to time and apply the proper boundary conditions to get:

\begin{equation} \label{equ:2d_wave_integrated}
    p_t + c^2\left ( u_x + v_y \right ) = 0.
\end{equation}

We can also write Equation~\ref{equ:2d_wave_integrated} in matrix form,

\begin{equation} \label{equ:2d_wave_matrix}
    \begin{bmatrix}
        p \\ 
        u \\ 
        v
    \end{bmatrix}_t +
    \begin{bmatrix}
        0 & c^2 & 0 \\ 
        1 & 0 & 0 \\ 
        0 & 0 & 0
    \end{bmatrix}
    \begin{bmatrix}
        p\\ 
        u\\ 
        v
    \end{bmatrix}_x + 
    \begin{bmatrix}
        0 & 0 & c^2 \\ 
        0 & 0 & 0 \\ 
        1 & 0 & 0
    \end{bmatrix}
    \begin{bmatrix}
        p\\ 
        u\\ 
        v
    \end{bmatrix}_y = 0,
\end{equation}

\noindent
or in vector form:

\begin{equation} \label{equ:2d_wave_vector}
    \mathbf{q_t} + B \mathbf{q_x} + C \mathbf{q_y} = 0,
\end{equation}

\noindent
where

\begin{equation} \label{equ:q}
    \mathbf{q}  = 
    \begin{bmatrix}
        p\\ 
        u\\ 
        v
    \end{bmatrix}.
\end{equation}

\(B\) and \(C\) are constant matrices and as such can be combined with the derivatives.

\begin{gather}
    \mathbf{f} = B \mathbf{q} \\
    \mathbf{g} = C \mathbf{q}
\end{gather}

\begin{equation}
    \mathbf{q_t} + \mathbf{f_x} + \mathbf{g_y} = 0
\end{equation}

By combining \(\mathbf{f}\) and \(\mathbf{g}\) into a flux vector \(\mathfrak{F}\), 

\begin{equation} \label{equ:2d_wave_fluxes}
    \mathfrak{F} = \mathbf{f}\widehat{x} + \mathbf{g}\widehat{y},
\end{equation}

\noindent
we get the conservative form of the wave equation:

\begin{equation} \label{equ:2d_wave_conservation}
    \mathbf{q_t} + \bigtriangledown \cdot \mathfrak{F} = 0,
\end{equation}

\noindent
where \(\widehat{x}\) and \(\widehat{y}\) are the unit vectors in the \(x\) and \(y\) directions,
respectively. 

We apply the divergence theorem to Equation~\ref{equ:2d_wave_conservation} to obtain two integrals,
one on the control volume \(V\) and one on the surface \(S\) of said volume.

\begin{equation} \label{equ:2d_wave_integral}
    \frac{d}{dt}\int_{V}\mathbf{q}dV = -\int_{S} \mathfrak{F} \cdot \widehat{n}dS
\end{equation}

\noindent
where \(\widehat{n}\) is the surface normal vector, pointing outwards.

\section{\glsentryshort{acr:DG-SEM}}\label{section:spectral_element_method:dg_sem}

Section~\ref{section:spectral_element_method:spectral_approximation} shows how to approximate
functions with polynomials and how to compute integrals on fixed intervals, for example \(\left[ -1,
1 \right]\). We must then apply those tools to arbitrary domains. Pure spectral approximations apply
the polynomials to the whole domain through a simple mapping. This can be problematic when
discontinuities or very steep solutions are present, as the finite order polynomials cannot match
the solution, and solutions exhibit oscillations. Also, these methods only work for simple domain
shapes, such as quadrilaterals, triangles and circles in 2D. To accommodate more complex domains,
such as blood vessels and airfoils, the method must be modified.

Patera proposed using \acrlongpl{acr:SEM}~\cite{Patera1984} to combine the accuracy of spectral
methods and the generality of finite element methods. Finite element methods can model complex
geometries by splitting the domain into multiple elements, with the equations being solved on the
elements. \Acrlongpl{acr:SEM} are used to solve a wide range of complex problems~\cite{Deville2003},
including the full Navier-Stokes equations. Continuous \acrlongpl{acr:SEM} use the Gauss-Lobatto
quadrature points to make sure the solution is continuous at element boundaries. These quadrature
points include points at \(-1\) and \(1\).

In this work, we use the \textit{\acrfull{acr:DG-SEM}}. The \acrshort{acr:DG-SEM} uses the Gauss
quadrature points described in
Subsection~\ref{subsection:spectral_element_method:spectral_approximation:basis_functions}. The
discontinuous Galerkin method, first proposed by Reed and Hill in 1973~\cite{Reed1973}, permits the
absence of quadrature points at the edges of the domain, letting the different elements be
discontinuous at their boundaries. These discontinuities are then counterbalanced by fluxes between
elements. Hesthaven and Warburton~\cite{Hesthaven2007} give a comprehensive reference on the
discontinuous Galerkin method. The present work follows the derivations from
Kopriva~\cite{Kopriva2009} for the \acrshort{acr:DG-SEM}. This method is especially well suited for
the intended work on \acrshortpl{acr:GPU}. It is highly accurate and geometrically flexible. It is
also easy to parallelise, as the discontinuities between elements make them independent. Each
element can be computed independently in parallel, then the fluxes are also computed in parallel.
The flux formulation also simplifies working with non-conforming interfaces, such as those resulting
of \acrlong{acr:AMR}, as described in
Section~\ref{section:adaptive_mesh_refinement:mortar_element_method}.

We start by deriving the discontinuous Galerkin approximation for a simple 2D domain spanning
\(\left[ -1, 1 \right] \times \left[ -1, 1 \right]\) shown in Figure~\ref{fig:simple_domain}.

\begin{figure}[H]
    \centering
    \includesvg[width=0.6\textwidth]{Chapter_spectral_element_method/media/domain}
    \caption{2D simple domain: \(\left[ -1, 1 \right] \times \left[ -1, 1 \right]\), with the four normals \(n_i\), i = 0, 1, 2, 3.}\label{fig:simple_domain}
\end{figure}

We approximate our solutions by polynomials of degree \(N\) in both directions, in Lagrange
form. 

\begin{gather}
    \mathbf{q} \approx \mathbf{Q} = \sum_{i = 0}^{N}\sum_{j = 0}^{N}\mathbf{Q}_{i j}l_i(x)l_j(y) \\
    \mathfrak{F} \approx \mathbf{F} = \sum_{i = 0}^{N} \sum_{j = 0}^{N} \left ( \mathbf{F}_{i j} \widehat{x} + \mathbf{G}_{i j}\widehat{y}\right ) l_i(x) l_j(y)
\end{gather}

where \(\mathbf{F}_{i j} \widehat{x} + \mathbf{G}_{i j}\widehat{y} = B \mathbf{Q}_{i j}\widehat{x}
+ C \mathbf{Q}_{i j}\widehat{y}\). 

We rewrite Equation~\ref{equ:2d_wave_conservation} in weak form, using the test functions \(v\).

\begin{equation} \label{equ:2d_wave_weak}
    \left( \mathbf{q_t}, v \right) + \left( \bigtriangledown \cdot \mathfrak{F}, v \right) = 0
\end{equation}

The test functions themselves can also be expressed in Lagrange form:

\begin{equation} \label{equ:test_lagrange}
    v = \sum^{N}_{i = 0}\sum_{j = 0}^{N}\widetilde{v}_{i j}l_i(x)l_j(y).
\end{equation}

Substituting Equation~\ref{equ:test_lagrange} in~\ref{equ:2d_wave_weak}, we obtain

\begin{equation}
    \sum_{i = 0}^{N}\sum_{j = 0}^{N} \left[ \int_{\Omega }\mathbf{q_t} l_i(x) l_j(y) dx dy + \int_{\Omega } \left( \bigtriangledown \cdot \mathfrak{F} \right) l_i(x) l_j(y) dx dy \right] \widetilde{v}_{i j} = 0,
\end{equation}

\noindent
where \(\Omega \) is the whole domain. Since \(\widetilde{v}_{i j}\) are arbitrary, the relation
must be true for all \(i,j\) independently. Therefore:

\begin{equation}
    \int_{\Omega} \mathbf{q_t} l_i(x) l_j(y) dx dy + \int_{\Omega } \left( \bigtriangledown \cdot \mathfrak{F} \right) l_i(x) l_j(y) dx dy = 0, \quad i,j = 0, \ldots, N
\end{equation}

\noindent
and

\begin{equation} % CHECK partial derivative?
    \int_{\Omega} \mathbf{Q}_t \phi_{i j} dx dy
    + \int _{\Omega} \bigtriangledown \cdot \mathbf{F} \phi_{i j} dx dy = 0, \quad i,j = 0, \ldots, N \label{equ:2d_wave_test}
\end{equation}

\noindent
with \(\phi_{i j} = l_i(x)l_j(y)\). We can then rewrite Equation~\ref{equ:2d_wave_test} in inner
product form: 

\begin{equation} \label{equ:2d_wave_inner_product}
    \left( \mathbf{Q}_t, \phi_{i j} \right) + \left( \bigtriangledown \cdot \mathbf{F}, \phi_{i j} \right) = 0.
\end{equation}

We then use Green's first identity to extract the boundary contribution from
Equation~\ref{equ:2d_wave_inner_product}'s second term. Green's first identity is stated as follows.

\begin{equation}
    \int_{\Omega} \bigtriangledown \cdot \left( \phi \mathbf{X} \right) d\Omega  = 
    \int_{\Omega} \bigtriangledown \phi \cdot \mathbf{X} + \phi \bigtriangledown \cdot \mathbf{X} d\Omega = \oint _{S} \phi \mathbf{X} \cdot \widehat{n} dS
\end{equation}

\noindent
where \(\Omega \) is the domain, and \(S\) is that domain's boundary. \(\phi \) is a scalar
function, and \(\mathbf{X}\) is a vector field. \(\widehat{n}\) is the boundary's normal vector,
pointing outwards. Applied to Equation~\ref{equ:2d_wave_inner_product}'s second term, we obtain:

\begin{equation} \label{equ:flux_green}
    \left( \bigtriangledown \cdot \mathbf{F}, \phi_{i j} \right) = \int_{-1}^{1}\int_{-1}^{1}\phi_{i j} \bigtriangledown \cdot \mathbf{F} dx dy = \oint_{S}\phi_{i j} \mathbf{F} \cdot \widehat{n}dS - \int_{-1}^{1}\int_{-1}^{1} \mathbf{F} \cdot \bigtriangledown \phi_{i j} dx dy.
\end{equation}

\noindent
The complete equation becomes:

\begin{equation} \label{equ:integral_equ}
    \left( \mathbf{Q}_t, \phi_{i j} \right) + \oint_{S}\phi_{i j} \mathbf{F}^* \cdot \widehat{n}dS - \int_{-1}^{1}\int_{-1}^{1} \mathbf{F} \cdot \bigtriangledown \phi_{i j} dx dy = 0.
\end{equation}

\noindent
The boundary conditions are weakly enforced using numerically computed boundary fluxes
\(\mathbf{F}^*\), as explained in Subsection~\ref{subsection:spectral_element_method:dg_sem:fluxes}. 

We then need to evaluate the integrals. A distinction is made between the interior terms that are
evaluated using the collocation points within an element shown in lilac in
Figure~\ref{fig:domain_nodes}, and the boundary term calculated at collocation points on the element
boundaries, shown in blue.

\begin{figure}[H]
    \centering
    \includesvg[width=0.4\textwidth]{Chapter_spectral_element_method/media/nodes}
    \caption{2D simple domain: Interior collocation points in lilac, boundary collocation points in blue.}\label{fig:domain_nodes}
\end{figure}

We start by applying Gauss quadrature to the first term of Equation~\ref{equ:integral_equ}.

\begin{equation}
    \begin{split}
        \int_{-1}^{1}\int_{-1}^{1} \mathbf{Q}_t \phi_{i j} dx dy 
        &= \int_{-1}^{1}\int_{-1}^{1}\mathbf{Q}_t l_i(x) l_j(y) dx dy \\
        &= \sum_{k = 0}^{N} \sum_{l = 0}^{N}\frac{d\mathbf{Q} \left( x_k, y_l \right)}{dt} l_i(x_k) l_j(y_l) w_k^{(x)} w_l^{(y)}
    \end{split}
\end{equation}

Since the integrand is a polynomial of degree \(2 N\), and the Gauss quadrature is exact for
polynomials up to \(2 N + 1\), the integral calculation is exact. We use the fact that only one
integrating polynomial \(l_i\) is equal to 1 and all others are 0 at each collocation point \(x_k\)
to get:

\begin{equation} \label{equ:integral_1}
    \int_{-1}^{1}\int_{-1}^{1} \mathbf{Q}_t \phi_{i j} dx dy 
    = \frac{d\mathbf{Q} \left( x_i, y_j \right)}{dt} w_i^{(x)} w_j^{(y)}.
\end{equation}

We do the same for the third term of Equation~\ref{equ:integral_equ}.

\begin{equation} \label{equ:integral_3}
    \begin{split}
        \int_{-1}^{1}\int_{-1}^{1}\mathbf{F} \cdot \bigtriangledown \phi_{i j} dx dy 
        &= \int_{-1}^{1}\int_{-1}^{1}\mathbf{F}(x, y) l'_i(x)l_j(y) + \mathbf{G}(x, y) l_i(x) l'_j(y) \: \: dx dy \\ 
        &= \sum_{k = 0}^{N} \sum_{l = 0}^{N}\left [ \mathbf{F}(x_k, y_l)l'_i(x_k)l_j(y_l) + \mathbf{G}(x_k, y_l) l_i(x_k)l'_j(y_l) \right ]w_k^{(x)} w_l^{(y)} \\
        &= \sum_{k = 0}^{N} \mathbf{F}(x_k, y_j)l'_i(x_k)w_k^{(x)} w_j^{(y)} + \sum_{l = 0}^{N}\mathbf{G}(x_i, y_l) l'_j(y_l) w_i^{(x)} w_l^{(y)}
    \end{split}
\end{equation}

Now only the second term is left, the integral over the boundary. We start by applying Gauss
quadrature to the developed integral.

\begin{equation} \label{equ:integral_2}
    \begin{split}
        \oint_{S} \phi_{i j}\mathbf{F}^* \cdot \widehat{n}dS = & 
        \int_{-1}^{1}l_i(x) l_j(-1)\mathbf{F}^*(x, -1) \cdot (-\widehat{y}) \: dx \\
        & + \int_{-1}^{1}l_i(x) l_j(1)\mathbf{F}^*(x, 1) \cdot (\widehat{y}) \: dx \\
        & + \int_{-1}^{1}l_i(-1) l_j(y)\mathbf{F}^*(-1, y) \cdot (-\widehat{x}) \: dy \\
        & + \int_{-1}^{1}l_i(1) l_j(y)\mathbf{F}^*(1, y) \cdot (\widehat{x}) \: dy \\
        = & \sum_{k = 0}^{N}l_i(x_k)l_j(-1)\mathbf{F}^*(x_k, -1)\cdot (-\widehat{y}) \: w_k^{(x)} \\
        & + \sum_{k = 0}^{N}l_i(x_k)l_j(1)\mathbf{F}^*(x_k, 1)\cdot (\widehat{y}) \: w_k^{(x)} \\
        & + \sum_{l = 0}^{N}l_i(-1)l_j(y_l)\mathbf{F}^*(-1, y_l)\cdot (-\widehat{x}) \: w_l^{(y)} \\
        & + \sum_{l = 0}^{N}l_i(1)l_j(y_l)\mathbf{F}^*(1, y_l)\cdot (\widehat{x}) \: w_l^{(y)} \\
        = & l_j(-1)\mathbf{F}^*(x_i, -1)\cdot (-\widehat{y}) \: w_i^{(x)} \\
        & + l_j(1)\mathbf{F}^*(x_i, 1)\cdot (\widehat{y}) \: w_i^{(x)} \\
        & + l_i(-1)\mathbf{F}^*(-1, y_j)\cdot (-\widehat{x}) \: w_j^{(y)} \\
        & + l_i(1)\mathbf{F}^*(1, y_j)\cdot (\widehat{x}) \: w_j^{(y)}
    \end{split}
\end{equation}

Note that the integrands are also of order \(2 N\), and are computed exactly. We put
Equations~\ref{equ:integral_1},~\ref{equ:integral_2} and~\ref{equ:integral_3} in
Equation~\ref{equ:integral_equ} and divide by the weights \(w_i^{ \left( x \right) } w_j^{ \left( y
\right) }\).

\begin{equation} \label{equ:2d_wave_full}
    \begin{split}
        & \frac{d\mathbf{Q}(x_i, y_j)}{dt} \\
        & + \left \{ \left[ l_i \left( -1 \right) \mathbf{F}^* \left( -1, y_j \right) \cdot \left( -\widehat{x} \right) \frac{1}{w_i^{ \left( x \right) }} + l_i \left( 1 \right) \mathbf{F}^* \left( 1, y_j \right) \cdot
        \left( \widehat{x} \right) \frac{1}{w_i^{ \left( x \right) }} \right] - \sum_{k = 0}^{N} \mathbf{F} \left(x_k, y_j \right) \frac{l'_i \left( x_k \right) w_k^{ \left( x \right) }}{w_i^{ \left( x \right) }} \right \} \\
        & + \left \{ \left[ l_j \left( -1 \right) \mathbf{F}^* (x_i, -1) \cdot \left( -\widehat{y} \right) \frac{1}{w_j^{ \left( y \right) }} + l_j \left( 1 \right) \mathbf{F}^*(x_i, 1) \cdot
        \left( \widehat{y} \right) \frac{1}{w_j^{ \left( y \right) }} \right] - \sum_{l = 0}^{N} \mathbf{G} \left(x_i, y_l \right) \frac{l'_j \left( y_l \right) w_l^{ \left( y \right) }}{w_j^{ \left( y \right) }} \right \} \\
        & = 0, \quad i,j = 0, \ldots, N
    \end{split} 
\end{equation}

We define \(l'_i(x_k)\) as the derivative matrix \(D_{k i}\). Since it is constant, we also
incorporate the weights \(w_i\) and \(w_k\).

\begin{equation} \label{equ:d_hat}
    \begin{split}
        \widehat{D}_{i k} = & -\frac{D_{k i} w_k}{w_i} \\
        = & -\frac{l'_i(x_k) w_k}{w_i}
    \end{split} 
\end{equation}

This simplifies Equation~\ref{equ:2d_wave_full} to:

\begin{equation} \label{equ:2d_wave_d}
    \begin{split}
        & \frac{d\mathbf{Q}(x_i, y_j)}{dt} \\
        & + \left \{ \left[ l_i \left( -1 \right) \mathbf{F}^* \left( -1, y_j \right) \cdot \left( -\widehat{x} \right) \frac{1}{w_i^{ \left( x \right) }} + l_i \left( 1 \right) \mathbf{F}^* \left( 1, y_j \right) \cdot
        \left( \widehat{x} \right) \frac{1}{w_i^{ \left( x \right) }} + \sum_{k = 0}^{N} \mathbf{F} \left( x_k, y_j \right) \widehat{D}_{i k}^{ \left( x \right) } \right] \right \} \\
        & + \left \{ \left [ l_j \left( -1 \right) \mathbf{F}^* \left( x_i, -1 \right) \cdot \left( -\widehat{y} \right) \frac{1}{w_j^{ \left( y \right) }} + l_j \left( 1 \right) \mathbf{F}^* \left(x_i, 1 \right) \cdot
        \left( \widehat{y} \right) \frac{1}{w_j^{ \left( y \right) }} + \sum_{l = 0}^{N} \mathbf{G} \left( x_i, y_l \right) \widehat{D}_{j l}^{ \left( y \right) } \right] \right \} \\
        & = 0, \quad i,j = 0, \ldots, N
    \end{split}
\end{equation}

The collocation points, weights and derivative matrices from Equation~\ref{equ:2d_wave_d} can be
computed directly and stored for the whole computation. Algorithms for those are discussed in
Section~\ref{section:spectral_element_method:implementation}. The next section discusses the
computation of the numerical boundary fluxes \(\mathbf{F}^*\).

\subsection{Fluxes}\label{subsection:spectral_element_method:dg_sem:fluxes}

We now need to compute the numerical fluxes \(\mathbf{F}^*\) to approximate the physical fluxes
\(\mathfrak{F}\). We recall the formulation for the fluxes from Equation~\ref{equ:2d_wave_integral}.
A more detailed derivation for the flux is found in~\cite{Kopriva2009}.

\begin{equation} \label{equ:physical_fluxes}
    \mathfrak{F} \cdot \widehat{n} = \mathbf{f} n_x + \mathbf{g} n_y = (B n_x + C n_y) \mathbf{q} = A \mathbf{q}
\end{equation}

\noindent
with matrices \(B\) and \(C\) taken from Equation~\ref{equ:2d_wave_matrix}.

\begin{equation}
    B = \begin{bmatrix}
        0 & c^2 & 0 \\ 
        1 & 0 & 0 \\ 
        0 & 0 & 0 
    \end{bmatrix}
    C = \begin{bmatrix}
        0 & 0 & c^2\\ 
        0 & 0 & 0 \\ 
        1 & 0 & 0
    \end{bmatrix}
\end{equation}

We also define the normal vector \(\widehat{n} = \alpha \widehat{x} + \beta \widehat{y} = n_x
\widehat{x} + n_y \widehat{y}\). We can then write the \(A\) matrix:

\begin{equation}
    A = \begin{bmatrix}
        0 & \alpha c^2 & \beta c^2 \\ 
        \alpha & 0 & 0 \\ 
        \beta & 0 & 0 
    \end{bmatrix}.
\end{equation}

We will use an upwind scheme~\cite{Toro2009} to calculate the flux at element interfaces. On an
interface between two elements, the left and right elements in that coordinate system, the state at
the interface is the left state if the wave goes from left to right, or the right state if the wave
goes from right to left. This is the upwind state of the elemental boundary.

Since it is not evident what the upwind state of the system is in
Equation~\ref{equ:physical_fluxes}, we will decouple the wave components. We decompose \(A\) into a
diagonal matrix \(\Lambda \), its right eigenvectors \(S\), and their inverse \(S^{-1}\).

\begin{equation}
    \Lambda = 
    \begin{bmatrix}
        c & 0 & 0 \\ 
        0 & -c & 0 \\ 
        0 & 0 & 0
    \end{bmatrix}
    S = 
    \begin{bmatrix}
        \frac{1}{2} & \frac{1}{2} & 0 \\ 
        \frac{\alpha}{2 c} & -\frac{\alpha}{2 c} & \beta \\ 
        \frac{\beta}{2 c} & -\frac{\beta}{2 c} & -\alpha 
    \end{bmatrix}
    S^{-1} = 
    \begin{bmatrix}
        1 & \alpha c & \beta c \\ 
        1 & -\alpha c & -\beta c \\ 
        0 & \beta & -\alpha
    \end{bmatrix}
\end{equation}

The diagonal matrix can be further decomposed into three wave directions: left-to-right,
right-to-left, and stationary.

\begin{equation}
    \begin{split}
        \Lambda & = 
        \begin{bmatrix}
            c & 0 & 0 \\ 
            0 & -c & 0 \\ 
            0 & 0 & 0
        \end{bmatrix} = 
        \begin{bmatrix}
            c & 0 & 0 \\ 
            0 & 0 & 0 \\ 
            0 & 0 & 0
        \end{bmatrix} +
        \begin{bmatrix}
            0 & 0 & 0 \\ 
            0 & -c & 0 \\ 
            0 & 0 & 0
        \end{bmatrix} +
        \begin{bmatrix}
            0 & 0 & 0 \\ 
            0 & 0 & 0 \\ 
            0 & 0 & 0
        \end{bmatrix} \\
        &= \Lambda^+ + \Lambda^- + \Lambda^0
    \end{split}
\end{equation}

We can then split the wave into three components, each containing only one direction.

\begin{equation}
    A = S \Lambda^+ S^{-1} + S \Lambda^- S^{-1} + S \Lambda^0 S^{-1} = A^+ + A^- + A^0
\end{equation}

We can evaluate the flux with:

\begin{equation} \label{equ:flux}
    \mathbf{F} \cdot \widehat{n} = A^+\mathbf{q} + A^-\mathbf{q} + A^0 \mathbf{q}.
\end{equation}

\begin{figure}[H]
    \centering
    \includesvg[width=0.25\textwidth]{Chapter_spectral_element_method/media/waves}
    \caption{States on both sides of an interface: The normal \(\widehat{n}\) of the interface
        determines the left and right sides. \(\mathbf{Q}^L\) and \(\mathbf{Q}^R\) are the states on
        the left and right of the interface, respectively. \(w^+\) and \(w^-\) indicate the
        left-to-right and right-to-left running waves, respectively.}\label{fig:waves}
\end{figure}

Figure~\ref{fig:waves} shows a boundary, with the associated states and waves. This guides us in
choosing the states \(\mathbf{q}\) in Equation~\ref{equ:flux}. The upwind state for the
left-to-right running wave is \(\mathbf{Q}^L\), and the upwind state for the right-to-left running
wave is \(\mathbf{Q}^R\). The stationary wave only has zeros in its matrix, and can be removed. This
gives us the formulation for the numerical fluxes. This is what is called the Riemann problem.

\begin{equation} \label{equ:flux_states}
    \mathbf{F}^* \cdot \widehat{n} = A^+ \mathbf{Q}^L + A^- \mathbf{Q}^R
\end{equation}

We can now compute the numerical fluxes. We define the characteristic variable \(\mathbf{W}\).

\begin{equation}
    \mathbf{W} = S^{-1} \mathbf{q} = 
    \begin{bmatrix}
        1 & \alpha c & \beta c \\ 
        1 & -\alpha c & -\beta c \\ 
        0 & \beta & -\alpha
    \end{bmatrix}
    \begin{bmatrix}
        p \\ 
        u \\ 
        v
    \end{bmatrix} = 
    \begin{bmatrix}
        p + c \left( \alpha u + \beta v \right) \\ 
        p - c \left( \alpha u + \beta v \right) \\ 
        \beta u - \alpha v
    \end{bmatrix} \equiv
    \begin{bmatrix}
        w^+ \\
        w^- \\
        w^0
    \end{bmatrix}   
\end{equation}

We define \(w^+\), \(w^-\) and \(w^0\) as the left-to-right, right-to-left and stationary waves,
respectively:

\begin{equation} \label{equ:waves_x}
    \begin{split}
        w^+ & \equiv p + c \left( \alpha u + \beta v \right) \\
        w^- & \equiv p - c \left( \alpha u + \beta v \right) \\
        w^0 & \equiv \beta u - \alpha v.
    \end{split} 
\end{equation}

Next, we multiply with the diagonal matrices \(\Lambda \), which contain the direction of the waves:

\begin{equation}
    \begin{split}
        \Lambda^+ \mathbf{W} & = 
        \begin{bmatrix}
            c & 0 & 0 \\ 
            0 & 0 & 0 \\ 
            0 & 0 & 0
        \end{bmatrix}
        \begin{bmatrix}
            w^+ \\
            w^- \\
            w^0
        \end{bmatrix} 
        = c
        \begin{bmatrix}
            w^+ \\
            0 \\
            0
        \end{bmatrix}, \\
        \Lambda^- \mathbf{W} & = 
        \begin{bmatrix}
            0 & 0 & 0 \\ 
            0 & -c & 0 \\ 
            0 & 0 & 0
        \end{bmatrix}
        \begin{bmatrix}
            w^+ \\
            w^- \\
            w^0
        \end{bmatrix} 
        = -c
        \begin{bmatrix}
            0 \\
            w^- \\
            0
        \end{bmatrix}, \\
        \Lambda^0 \mathbf{W} & = 
        \begin{bmatrix}
            0 & 0 & 0 \\ 
            0 & 0 & 0 \\ 
            0 & 0 & 0
        \end{bmatrix}
        \begin{bmatrix}
            w^+ \\
            w^- \\
            w^0
        \end{bmatrix} 
        = 
        \begin{bmatrix}
            0 \\
            0 \\
            0
        \end{bmatrix}.
    \end{split}
\end{equation}

\noindent
Finally, multiplying by \(S\), we get the full numerical flux:

\begin{equation} \label{equ:numerical_flux}
    \mathbf{F}^* \cdot \widehat{n} = 
    S \Lambda^+ S^{-1} \mathbf{\mathbf{Q}^L} + S \Lambda^- S^{-1} \mathbf{\mathbf{Q}^R} =
    \begin{bmatrix}
        \frac{c}{2} \left( w^{+, L} - w^{-, R} \right) \\
        \frac{n_x}{2} \left( w^{+, L} + w^{-, R} \right) \\
        \frac{n_y}{2} \left( w^{+, L} + w^{-, R} \right)
    \end{bmatrix}.
\end{equation}

\noindent
The superscripts \(L\) and \(R\) indicate which state is used, according to
Equation~\ref{equ:flux_states}. 

With the relation~\ref{equ:numerical_flux}, we can compute the numerical fluxes. The algorithm used
to compute these fluxes is presented in
Subsection~\ref{subsection:spectral_element_method:implementation:fluxes}. It is commonly known as
the Riemann solver.

\subsection{Time integration}\label{subsection:spectral_element_method:dg_sem:time}

Now that we know how to compute the interior terms and the numerical fluxes of
Equation~\ref{equ:2d_wave_d}, we can compute the time derivative \(\mathbf{Q}_t\). We need to
integrate the equation in time. We will use a third-order low-storage Runge-Kutta method, as
described by Williamson~\cite{Williamson1980}. As the name suggests, this method uses low memory to
attain high temporal accuracy. This is especially useful in the context of \acrshort{acr:GPU}
computation, as \acrshortpl{acr:GPU} tend to have less available memory than usual
\acrshort{acr:HPC} \acrshort{acr:CPU} platforms. This method requires \(2 N\) storage, where \(N\)
is the number of variables. Concretely, we will need to store the computed time derivatives in
temporary arrays, which will then be added to the real time derivative arrays.

The method works as follows. For a differential equation

\begin{equation}
    u_t = H(u, t),
\end{equation}

\noindent
we will use \(\Delta t\) to represent the time step, \(n\) to represent the number of time steps
thus far, and \(t_n = n \Delta t\) as the current time. \(u\) is the solution vector with \(N\)
variables, and \(U^n\) is the approximation of the solution at \(t_n\). The method gives the
approximation of the solution at the next timestep as:

\begin{equation} \label{equ:runge_kutta}
    \begin{split}
        & U \leftarrow U^n \\
        & T \leftarrow H \left( U, t_n \right) \\
        & U \leftarrow U + \frac{1}{3} \Delta t T \\
        & T = -\frac{5}{9} T + H \left( U, t_n + \frac{1}{3} \Delta t \right) \\
        & U \leftarrow U + \frac{15}{16} \Delta t T \\
        & T \leftarrow -\frac{153}{128} T + H \left( U, t_n + \frac{3}{4} \Delta t \right) \\
        & U^{n + 1} \leftarrow U + \frac{8}{15} \Delta t T
    \end{split}
\end{equation}

\(T\) is introduced as a temporary variable to store the time derivative after partial time steps.
As \(U\) and \(T\) are overwritten at each of the three stages, the storage required is only \(2
N\), where \(N\) is the number of variables making up \(U\). The algorithm can be summarised as the
following stage run three times, where \(m\) is the stage number.

\begin{equation} \label{equ:runge_kutta_stage}
    \begin{split}
        & T \leftarrow a_m T + H \left( U, t_n + b_m \Delta t \right) \\
        & U \leftarrow U + g_m \Delta t T
    \end{split}
\end{equation}

The following table lists the coefficients \(a_m\), \(b_m\) and \(g_m\).

\begin{table}[H]
    \centering
    \begin{tabular}{c c c c}
        \(m\) & \(a_m\) & \(b_m\) & \(g_m\) \\
        \midrule
        0 & 0 & 0 & \(\frac{1}{3}\) \\
        1 & \(-\frac{5}{9}\) & \(\frac{1}{3}\) & \(\frac{15}{16}\) \\
        2 & \(-\frac{153}{128}\) & \(\frac{3}{4}\) & \(\frac{8}{15}\) \\
    \end{tabular}
    \caption{Coefficients of the third-order low storage Runge-Kutta method.}\label{table:runge_kutta_coefficient}
\end{table}

This method is an explicit time stepping method, therefore we have to fulfill the
\textit{\acrfull{acr:CFL}} condition on the time step size to ensure stability. The
\acrshort{acr:CFL} condition is stated as:

\begin{equation}
    \left| \frac{c \Delta t}{\Delta x} \right| \leq \CFL
\end{equation}

\noindent
where the \(\CFL \) number is usually 1. As we have a higher-order time integration scheme, the
\(\CFL \) number can be increased above this number~\cite{Gottlieb2001}.

To account for the uneven spacing between the collocation points inside an element, we will estimate
the smallest spacing in an element as: 

\begin{equation}
    \Delta x = \frac{\Delta l_k}{N^2}
\end{equation}

\noindent
where \(\Delta l_k\) is the minimum length of element \(k\), and \(N\) is the polynomial
order of that element. The global timestep will be chosen as the minimum timestep of all elemental
timesteps. 

\begin{equation}
    \Delta t = \min_{k \in 0:K} \left( \Delta t_k \right)
\end{equation}

\begin{equation}
    \Delta t_k \leq \CFL \frac{\Delta l_k}{cN^2}
\end{equation}

\section{Implementation}\label{section:spectral_element_method:implementation}

\subsection{Fluxes}\label{subsection:spectral_element_method:implementation:fluxes}

Algorithm~\ref{alg:wave_fluxes} shows how fluxes are computed on the \acrshort{acr:GPU}. This
function is a good example of measures that have to be taken in order to avoid race conditions when
performing computations in parallel on \acrshortpl{acr:GPU}. In most of the program, we parallelise
over elements, with each thread performing computations on elements. When computing fluxes, both
elements on either side of a face add their contribution to the face. In addition, an element can
have multiple faces on each side, a side effect of the non-conforming interfaces from
Section~\ref{section:adaptive_mesh_refinement:mortar_element_method}. If we parallelise over
elements, race conditions will occur when multiple elements try to add their contribution to the
same face at the same time. The possibility then arises that the contribution of some elements would
be dropped if it is overwritten by another element. This is not a problem for serial or
multi-process single threaded \acrshort{acr:CPU} programs.

To remedy this, we parallelise over faces for the flux computation. Earlier computations, also
parallelised over faces, project the boundary solution of both elements to two solution arrays, left
and right, in the face objects. The flux computation can then compute the fluxes and store them in a
single flux solution array in the face objects. Afterwards, we will be able to once again
parallelise over elements to project these fluxes back to the elements, and continue the normal
execution of the program.

\begin{algorithm}[H]
    \begin{cuda}
        __global__
        auto calculate_wave_fluxes(size_t N_faces, Face2D_t* faces) -> void {
            const int index = blockIdx.x * blockDim.x + threadIdx.x;
            const int stride = blockDim.x * gridDim.x;

            for (size_t face_index = index; face_index < N_faces; face_index += stride) {
                Face2D_t& face = faces[face_index];

                // Computing fluxes
                for (int i = 0; i <= face.N_; ++i) {
                    const Vec2<deviceFloat> u_L {face.u_[0][i], face.v_[0][i]};
                    const Vec2<deviceFloat> u_R {face.u_[1][i], face.v_[1][i]};

                    const deviceFloat w_L = face.p_[0][i] + Constants::c * u_L.dot(face.normal_);
                    const deviceFloat w_R = face.p_[1][i] - Constants::c * u_R.dot(face.normal_);

                    face.p_flux_[i] = Constants::c * (w_L - w_R) / 2;
                    face.u_flux_[i] = face.normal_.x() * (w_L + w_R) / 2;
                    face.v_flux_[i] = face.normal_.y() * (w_L + w_R) / 2;
                }
            }
        }\end{cuda}
\caption{\textbf{calculate\_wave\_fluxes:} Riemann solver for the wave equation fluxes.}\label{alg:wave_fluxes}
\end{algorithm}
