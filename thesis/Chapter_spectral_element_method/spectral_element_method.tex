\chapter{Discontinuous Galerkin Spectral Element Method} \label{chapter:spectral_element_method}

We will use the \textit{discontinuous Galerkin spectral element method (DG-SEM)} to solve the 2D
wave equation. This method is part of the broader class of spectral methods, applied within local
elements as in finite-element methods. This method exhibits the exponential convergence of spectral
methods, while adding the ability to model difficult geometries of finite-element methods. The
method is described in~\cite{Kopriva2009}, along with efficient computer programming implementation
strategies. The main model problem showcased throughout this work depicts a wave moving diagonally
through a square domain.

\section{Spectral approximation} \label{section:spectral_element_method:spectral_approximation}
% Legendre polynomials, both forms
% Polynomial interpolation

Spectral methods, as described by Gottlieb and Orszag~\cite{Gottlieb1977}, model functions as sums
of weighted orthogonal functions, often polynomials. Let us denote $\phi_n(x)$ as the polynomial of
degree $n$, and $a_n$ as the weight of said polynomial. The weights make up the spectrum of the
solution.

\begin{equation} \label{equ:infinite_sum}
    \begin{split}
        f(x) & = \sum_{n = 0}^{\infty }a_n \phi_n(x)
    \end{split}
\end{equation}

Since it is impractical to sum an infinite number of polynomials on a computer, the sum is truncated
to a polynomial order $N$. This becomes the polynomial order of the approximation. The truncated
part becomes $\tau$, the truncation error.

\begin{equation} \label{equ:truncated_sum}
    \begin{split}
        f(x) & = \sum_{n = 0}^{\infty }a_n \phi_n(x) \\
        & = \sum_{n = 0}^{N}a_n \phi_n(x) + \sum_{n = N + 1}^{\infty }a_n \phi_n(x) \\
        & = \sum_{n = 0}^{N}a_n \phi_n(x) + \tau \\
        & \approx \sum_{n = 0}^{N}a_n \phi_n(x)
    \end{split}
\end{equation}

Since we discard part of the spectrum, it is important that the retained polynomial terms capture
the essential parts of the solution. We therefore want the weights to decay as fast as possible.
This will be a characteristic of the polynomials we choose. For example, Fourier series, Legendre
polynomials and Chebyshev polynomials have been proved~\cite{Kopriva2009} to have exponentially
decaying coefficients, giving them spectral accuracy.

\subsection{Basis functions} \label{section:spectral_element_method:spectral_approximation:basis_functions}

Spectral methods exploit the orthogonality property of sets of functions. For orthogonal
functions in the domain $[a, b]$, we have:

\begin{equation} \label{equ:orthogonality}
	\int_{a}^{b}\phi_i(x) \phi_j(x)dx = C_i \delta_{ij}
\end{equation}

\noindent
with $C_i$ being a constant, and $\delta_{ij}$ being the Kronecker delta, defined as such:

\begin{equation} \label{equ:kronecker}
	\delta _{ij} = \left\{ \begin{matrix}
                    1, & if \:\: i = j,\\ 
                    0, & if \:\: i \neq j.
                    \end{matrix} \right.
\end{equation}

The inner product of two functions $f \left( x \right)$ and $g \left( x \right)$ continuous in
$\left[ a, b \right]$, is:

\begin{equation}
    \left( f, g \right) = \int_{a}^{b}f(x)g(x)dx
\end{equation}

\noindent
We can therefore rewrite Equation~\ref{equ:orthogonality} in inner product form:

\begin{equation}
	\left( \phi_i, \phi_j \right) = \int_{a}^{b}\phi_i(x) \phi_j(x)dx = C_i \delta_{ij}
\end{equation}

The high-order orthogonal polynomials we use have associated weights $w$ that ensures orthogonality
of the polynomials. $D_{ij}$ is a constant.

\begin{equation}
	\left ( \phi_i, \phi_j \right ) = \int_a^b \phi_i(x)\phi_j(x)w(x)dx = D_{ij}\delta_{ij}
\end{equation}

Fourier series can be used for periodic problems. As for non-periodic problems, Legendre polynomials
and Chebyshev polynomials fit these criteria. Legendre polynomials have a weighting function of
$w(x) = 1$, which simplifies computations. We will therefore use the Legendre polynomials.

\begin{figure}[H]
	\centering
	\includesvg[width=0.8\textwidth]{Chapter_spectral_element_method/media/polynomials}
	\caption{Legendre polynomials: The first six Legendre polynomials.}
	\label{fig:polynomials}
\end{figure}

The Legendre polynomials were discovered by Adrien-Marie Legendre in 1782. Using their associated
weights $w(x) = 1$ and the interval $\left[ -1, 1 \right]$, the polynomials are orthogonal. The
Legendre polynomials $L_k \left( x \right)$ of degree $k$ therefore have the property:

\begin{equation}
	\int_{-1}^{1}L_{k_1}(x) L_{k_2}(x) dx = 0, \quad if \:\: k_1 \neq k_2.
\end{equation}

The Legendre polynomials can be generated using a three-term recursive formula. Knowing that the
first two polynomials are $L_0 \left( x \right) = 1$ and $L_1 \left( x \right) = x$, all subsequent
polynomials can be generated from the following formula.

\begin{equation} \label{equ:three_terms}
	L_{k + 1}(x) = \frac{2k + 1}{k + 1}xL_k(x) - \frac{k}{k + 1}L_{k - 1}(x)
\end{equation}

These polynomials will help us compute integrals using Gauss quadrature. For an interval $\left[ -1, 1
\right]$, the Gauss quadrature formula is:

\begin{equation}
	\int_{-1}^{1}f(x)dx \approx \sum_{i = 0}^{N}w_i f(x_i).
\end{equation}

The points $x_i$ used for the quadrature are the Gauss quadrature points, or collocation points.
Using the roots of the (N + 1)\textsuperscript{th} Legendre polynomial, the quadrature is exact for
polynomials of degree $\leq 2 N + 1$. This is the \textit{Gauss-Legendre quadrature rule}. We use
the roots of the (N + 1)\textsuperscript{th} Legendre polynomial to get the points $x_i$ and weights
$w_i$.

\begin{gather}
	x_i = roots \:\: of \:\: L_{N + 1}(x), \quad i = 0, ..., N \\
	w_i = \frac{2}{(1-x_i^2)\left [ L'_{N + 1}(x_i) \right ]^2}
\end{gather}

\subsection{Polynomial interpolation} \label{section:spectral_element_method:spectral_approximation:polynomial_interpolation}

Polynomial interpolation fits data to a polynomial passing through known points. The polynomial has
an order equal to the number of points. In this work we use Lagrange integrating polynomials $l_j$
of degree N.

\begin{equation}
	l_j(x) = \prod_{\substack{i = 0 \\ i \neq j}}^{N}\frac{x- x_i}{x_j - x_i}
\end{equation}

At each collocation point $x_i$ only one of the integrating polynomials has the value 1, the others
having a value of 0. This mimics the Kronecker delta $\delta_{ij}$.

\begin{equation}
	l_j(x_i) = \delta_{ij} = \left\{\begin{matrix}
	1, \quad i = j\\ 
	0, \quad i \neq j,
	\end{matrix}\right.
\end{equation}

Figure~\ref{fig:interpolants} displays the interpolating polynomials of degree six:

\begin{figure}[H]
	\centering
	\includesvg[width=0.8\textwidth]{Chapter_spectral_element_method/media/interpolants}
	\caption{Polynomial interpolation: The Lagrange integrating polynomials of degree six.}
	\label{fig:interpolants}
\end{figure}

With this, we can interpolate a function $p_N \left( x \right)$ of degree N:

\begin{equation}
	p_N(x) = \sum_{j = 0}^{N}p(x_j)l_j(x).
\end{equation}

We can also modify the Lagrange interpolation to the barycentric form.

\begin{gather}
	p_N(x) = \psi(x)\sum_{j = 0}^{N}p(x_j)\frac{w_j}{x - x_j} \\
	\psi(x) = \prod_{i = 0}^{N}\left ( x - x_i \right ) \\
	w_j = \frac{1}{\prod_{\genfrac{}{}{0pt}{2}{i = 0}{i \neq j}}^{N}(x_j - x_i)}
\end{gather}

\noindent
We retain the same property as the initial form:

\begin{equation}
	\psi(x)\sum_{j = 0}^{N}\frac{w_j}{x - x_j} = 1.
\end{equation}

We can then rewrite the complete Lagrange interpolation in barycentric form. By pre-computing the
barycentric weights $w_j$, we can compute the interpolated value at any point $x$ using only the
known values at the collocation points, without computing the interpolating polynomials. 

\begin{equation}
	p_N(x) = \frac{\sum_{j = 0}^{N} p(x_j)\frac{w_j}{x - x_j}}{\sum_{j = 0}^{N}\frac{w_j}{x - x_j}}
\end{equation}

\section{The Wave Equation Model} \label{section:spectral_element_method:equation}

We want to solve the 2D wave equation:

\begin{gather}
	\frac{\partial^2p}{\partial t^2} - c^2(p_{xx} + p_{yy}) = 0 \\
	u_t = - p_x \\
	v_t = -p_y
\end{gather}

With $p$ being the pressure, $u$ and $v$ being the two components of the velocity, and $c$ being the
sound speed. The three equations can be combined into one.

\begin{equation} \label{equ:2d_wave}
	\frac{\partial^2p}{\partial t^2} + c^2\left ( (u_x)_t + (v_y)_t \right ) = 0
\end{equation}

We then integrate once with respect to time, to get:

\begin{equation} \label{equ:2d_wave_integrated}
	p_t + c^2\left ( u_x + v_y \right ) = 0.
\end{equation}

We can also write Equation~\ref{equ:2d_wave_integrated} in matrix form,

\begin{equation} \label{equ:2d_wave_matrix}
	\begin{bmatrix}
        p \\ 
        u \\ 
        v
	\end{bmatrix}_t +
	\begin{bmatrix}
        0 & c^2 & 0 \\ 
        1 & 0 & 0 \\ 
        0 & 0 & 0
	\end{bmatrix}
	\begin{bmatrix}
        p\\ 
        u\\ 
        v
	\end{bmatrix}_x + 
	\begin{bmatrix}
        0 & 0 & c^2 \\ 
        0 & 0 & 0 \\ 
        1 & 0 & 0
	\end{bmatrix}
	\begin{bmatrix}
        p\\ 
        u\\ 
        v
	\end{bmatrix}_y = 0,
\end{equation}

\noindent
or in vector form:

\begin{equation} \label{equ:2d_wave_vector}
	\mathbf{q_t} + B \mathbf{q_x} + C \mathbf{q_y} = 0.
\end{equation}

$B$ and $C$ are constant matrices, and as such can be combined with the derivatives.

\begin{gather}
	\mathbf{f} = B \mathbf{q} \\
	\mathbf{g} = C \mathbf{q}
\end{gather}

\begin{equation}
	\mathbf{q_t} + \mathbf{f_x} + \mathbf{g_y} = 0
\end{equation}

By combining $\mathbf{f}$ and $\mathbf{g}$ into a flux vector $\mathfrak{F}$, 

\begin{equation} \label{equ:2d_wave_fluxes}
	\mathfrak{F} = \mathbf{f}\widehat{x} + \mathbf{g}\widehat{y},
\end{equation}

\noindent
we get the conservative form of the wave equation.

Where $\widehat{x}$ and $\widehat{y}$ are the unit vectors in the $x$ and $y$ directions,
respectively. 

\begin{equation} \label{equ:2d_wave_conservation}
	\mathbf{q_t} + \bigtriangledown \cdot \mathfrak{F} = 0
\end{equation}

We apply the divergence theorem to Equation~\ref{equ:2d_wave_conservation} to obtain two integrals,
one on the control volume $V$ and one on the surface $S$ of said volume.

\begin{equation} \label{equ:2d_wave_integral}
	\frac{d}{dt}\int_{V}\mathbf{q}dV = -\int_{S}\mathfrak{F}\cdot \widehat{n}dS
\end{equation}

\noindent
Where $\widehat{n}$ is the surface normal vector, pointing outwards.

\section{DG-SEM} \label{section:spectral_element_method:dg_sem}

Section~\ref{section:spectral_element_method:spectral_approximation} shows how to approximate
functions with polynomials and how to compute integrals on fixed intervals, for example $\left[ -1,
1 \right]$. We must then apply those tools to arbitrary domains. Pure spectral approximations apply
the polynomials to the whole domain through a simple mapping. This can be problematic when
discontinuities or very steep solutions are present, as the finite order polynomials cannot match
the solution, and solutions exhibit oscillations. Also, these methods only work for simple domain
shapes, such as quadrilaterals, triangles and circles in 2D. To accommodate more complex domains,
such as blood vessels and airfoils, the method must be modified.

Patera proposed using spectral element methods~\cite{Patera1984} to combine the accuracy of spectral
methods and the generality of finite element methods. Finite element methods can model complex
geometries by splitting the domain into multiple elements, with the equations being solved on the
elements. Spectral element methods are used to solve a wide range of complex
problems~\cite{Deville2003}, including the full Navier-Stokes equations. Continuous spectral element
methods use the Gauss-Lobatto quadrature points to make the solution is made continuous at element
boundaries. These quadrature points include points at $-1$ and $1$.

In this work, we use the discontinuous Galerkin spectral element method. The DG-SEM uses the Gauss
quadrature points described in
Subsection~\ref{section:spectral_element_method:spectral_approximation:basis_functions}. The
discontinuous Galerkin method, first proposed by Reed and Hill in 1973~\cite{Reed1973}, permits the
absence of quadrature points at the edges of the domain lets the different elements be discontinuous
at their boundaries. These discontinuities are then counterbalanced by fluxes between elements.
Hesthaven and Warburton~\cite{Hesthaven2007} showed a comprehensive reference on the discontinuous
Galerkin methods. This work follows the derivations from Kopriva~\cite{Kopriva2009} for the DG-SEM.
This method is especially well suited for this program. It is accurate and geometrically flexible.
It is also easy to parallelise, as the discontinuities between elements make them independent.
Each element can be computed independently in parallel, then the fluxes are also computed in
parallel.

We start by deriving the discontinuous Galerkin approximation for a simple 2D domain spanning
$\left[ -1, 1 \right] \times \left[ -1, 1 \right]$ shown in Figure~\ref{fig:simple_domain}.

\begin{figure}[H]
	\centering
	\includesvg[width=0.6\textwidth]{Chapter_spectral_element_method/media/domain}
	\caption{2D simple domain: $\left[ -1, 1 \right] \times \left[ -1, 1 \right]$, with the four normals $n_i$, i = 0, 1, 2, 3.}
	\label{fig:simple_domain}
\end{figure}

We approximate our solutions by polynomials of degree $N$ in both directions, in Lagrange
form. 

\begin{gather}
	\mathbf{q} \approx \mathbf{Q} = \sum_{i = 0}^{N}\sum_{j = 0}^{N}\mathbf{Q}_{i,j}l_i(x)l_j(y) \\
	\mathfrak{F} \approx \mathbf{F} = \sum_{i = 0}^{N} \sum_{j = 0}^{N} \left ( \mathbf{F}_{i, j} \widehat{x} + \mathbf{G}_{i, j}\widehat{y}\right ) l_i(x) l_j(y)
\end{gather}

Where $\mathbf{F}_{i, j} \widehat{x} + \mathbf{G}_{i, j}\widehat{y} = B \mathbf{Q}_{i, j}\widehat{x}
+ C \mathbf{Q}_{i, j}\widehat{y}$. 

We rewrite Equation~\ref{equ:2d_wave_conservation} in weak form, using the test functions $v$.

\begin{equation} \label{equ:2d_wave_weak}
	\left( \mathbf{q_t}, v \right) + \left( \bigtriangledown \cdot \mathfrak{F}, v \right) = 0
\end{equation}

The test functions themselves can also be expressed in Lagrange form:

\begin{equation} \label{equ:test_lagrange}
	v = \sum^{N}_{i = 0}\sum_{j = 0}^{N}\widetilde{v}_{i, j}l_i(x)l_j(y).
\end{equation}

Substituting Equation~\ref{equ:test_lagrange} in~\ref{equ:2d_wave_weak}, we obtain

\begin{equation}
	\sum_{i = 0}^{N}\sum_{j = 0}^{N} \left[ \int_{\Omega }\mathbf{q_t} l_i(x) l_j(y) dx dy + \int_{\Omega } \left( \bigtriangledown \cdot \mathfrak{F} \right) l_i(x) l_j(y) dx dy \right] \widetilde{v}_{i, j} = 0,
\end{equation}

\noindent
where $\Omega$ is the whole domain. Since $\widetilde{v}_{i, j}$ are arbitrary, the relation must be
true for all $i,j$ independently. Therefore:

\begin{equation}
    \int_{\Omega} \mathbf{q_t} l_i(x) l_j(y) dx dy + \int_{\Omega } \left( \bigtriangledown \cdot \mathfrak{F} \right) l_i(x) l_j(y) dx dy = 0, \quad i,j = 0, ..., N
\end{equation}

\noindent
and

\begin{equation} % CHECK partial derivative?
    \int_{\Omega} \frac{d\mathbf{Q}}{dt} \phi_{i, j} dx dy
    + \int _{\Omega} \bigtriangledown \cdot \mathbf{F} \phi_{i, j} dx dy = 0, \quad i,j = 0, ..., N \label{equ:2d_wave_test}
\end{equation}

\noindent
with $\phi_{i, j} = l_i(x)l_j(y)$. We can then rewrite Equation~\ref{equ:2d_wave_test} in inner
product form: 

\begin{equation} \label{equ:2d_wave_inner_product}
	\left( \mathbf{Q}_t, \phi_{i, j} \right) + \left( \bigtriangledown \cdot \mathbf{F}, \phi_{i, j} \right) = 0
\end{equation}

We then use Green's first identity to extract the boundary contribution from
Equation~\ref{equ:2d_wave_inner_product}'s second term. Green's first identity goes as follows.

\begin{equation}
    \int_{\Omega} \bigtriangledown \cdot \left( \phi \mathbf{X} \right) d\Omega  = 
    \int_{\Omega} \bigtriangledown \phi \cdot \mathbf{X} + \phi \bigtriangledown \cdot \mathbf{X} d\Omega = \oint _{S} \phi \mathbf{X} \cdot \widehat{n} dS
\end{equation}

Where $\Omega$ is the domain, and $S$ is that domain's boundary. $\phi$ is a scalar function, and
$\mathbf{X}$ is a vector field. $\widehat{n}$ is the boundary's normal vector, pointing outwards.
Applied to Equation~\ref{equ:2d_wave_inner_product}'s second term, we get:

\begin{equation} \label{equ:flux_green}
    \left( \bigtriangledown \cdot \mathbf{F}, \phi_{i, j} \right) = \int_{-1}^{1}\int_{-1}^{1}\phi_{i, j} \bigtriangledown \cdot \mathbf{F} dx dy = \oint_{S}\phi_{i, j} \mathbf{F} \cdot \widehat{n}dS - \int_{-1}^{1}\int_{-1}^{1} \mathbf{F} \cdot \bigtriangledown \phi_{i, j} dx dy.
\end{equation}

\noindent
The complete equation becomes:

\begin{equation} \label{equ:integral_equ}
    \left( \mathbf{Q}_t, \phi_{i, j} \right) + \oint_{S}\phi_{i, j} \mathbf{F}^* \cdot \widehat{n}dS - \int_{-1}^{1}\int_{-1}^{1} \mathbf{F} \cdot \bigtriangledown \phi_{i, j} dx dy = 0.
\end{equation}

The boundary conditions are weakly enforced using fluxes $\mathbf{F}^*$, as explained in
Subsection~\ref{section:spectral_element_method:dg_sem:fluxes}. 

We then need to evaluate the integrals. A distinction is made between the boundary terms, that are
evaluated using the collocation points within an element, and the boundary term, which uses
collocation points on the element boundaries.

\begin{figure}[H]
	\centering
	\includesvg[width=0.4\textwidth]{Chapter_spectral_element_method/media/nodes}
	\caption{2D simple domain: Interior collocation points in lilac, boundary collocation points in blue.}
	\label{fig:domain_nodes}
\end{figure}

We start by applying Gauss quadrature to the first term of Equation~\ref{equ:integral_equ}.

\begin{equation}
	\begin{split}
        \int_{-1}^{1}\int_{-1}^{1} \mathbf{Q}_t \phi_{i, j} dx dy 
        &= \int_{-1}^{1}\int_{-1}^{1}\mathbf{Q}_t l_i(x) l_j(y) dx dy \\
        &= \sum_{k = 0}^{N} \sum_{l = 0}^{N}\frac{d\mathbf{Q} \left( x_k, y_l \right)}{dt} l_i(x_k) l_j(y_l) w_k^{(x)} w_l^{(y)}
	\end{split}
\end{equation}

Since the integrand is a polynomial of degree $2 N$, and the Gauss quadrature is exact for
polynomials up to $2 N + 1$, the integral calculation is exact. We use the fact that only one integrating
polynomial $l_i$ is equal to 1 and not 0 on each collocation point $x_k$ to get:

\begin{equation} \label{equ:integral_1}
    \int_{-1}^{1}\int_{-1}^{1} \mathbf{Q}_t \phi_{i, j} dx dy 
    = \frac{d\mathbf{Q} \left( x_i, y_j \right)}{dt} w_i^{(x)} w_j^{(y)}.
\end{equation}

We do the same for the third term of Equation~\ref{equ:integral_equ}.

\begin{equation} \label{equ:integral_3}
	\begin{split}
		\int_{-1}^{1}\int_{-1}^{1}\mathbf{F} \cdot \bigtriangledown \phi_{i, j} dx dy 
		&= \int_{-1}^{1}\int_{-1}^{1}\mathbf{F}(x, y) l'_i(x)l_j(y) + \mathbf{G}(x, y) l_i(x) l'_j(y) \:\: dx dy \\ 
		&= \sum_{k = 0}^{N} \sum_{l = 0}^{N}\left [ \mathbf{F}(x_k, y_l)l'_i(x_k)l_j(y_l) + \mathbf{G}(x_k, y_l) l_i(x_k)l'_j(y_l) \right ]w_k^{(x)} w_l^{(y)} \\
		&= \sum_{k = 0}^{N} \mathbf{F}(x_k, y_j)l'_i(x_k)w_k^{(x)} w_j^{(y)} + \sum_{l = 0}^{N}\mathbf{G}(x_i, y_l) l'_j(y_l) w_i^{(x)} w_l^{(y)}
	\end{split}
\end{equation}

Now only the second term is left, the integral over the boundary. We start by applying Gauss
quadrature to the developed integral.

\begin{equation} \label{equ:integral_2}
	\begin{split}
        \oint_{S} \phi_{i, j}\mathbf{F}^* \cdot \widehat{n}dS = & 
        \int_{-1}^{1}l_i(x) l_j(-1)\mathbf{F}^*(x, -1) \cdot (-\widehat{y}) \: dx \\
        & + \int_{-1}^{1}l_i(x) l_j(1)\mathbf{F}^*(x, 1) \cdot (\widehat{y}) \: dx \\
        & + \int_{-1}^{1}l_i(-1) l_j(y)\mathbf{F}^*(-1, y) \cdot (-\widehat{x}) \: dy \\
        & + \int_{-1}^{1}l_i(1) l_j(y)\mathbf{F}^*(1, y) \cdot (\widehat{x}) \: dy \\
        = & \sum_{k = 0}^{N}l_i(x_k)l_j(-1)\mathbf{F}^*(x_k, -1)\cdot (-\widehat{y}) \: w_k^{(x)} \\
        & + \sum_{k = 0}^{N}l_i(x_k)l_j(1)\mathbf{F}^*(x_k, 1)\cdot (\widehat{y}) \: w_k^{(x)} \\
        & + \sum_{l = 0}^{N}l_i(-1)l_j(y_l)\mathbf{F}^*(-1, y_l)\cdot (-\widehat{x}) \: w_l^{(y)} \\
        & + \sum_{l = 0}^{N}l_i(1)l_j(y_l)\mathbf{F}^*(1, y_l)\cdot (\widehat{x}) \: w_l^{(y)} \\
        = & l_j(-1)\mathbf{F}^*(x_i, -1)\cdot (-\widehat{y}) \: w_i^{(x)} \\
        & + l_j(1)\mathbf{F}^*(x_i, 1)\cdot (\widehat{y}) \: w_i^{(x)} \\
        & + l_i(-1)\mathbf{F}^*(-1, y_j)\cdot (-\widehat{x}) \: w_j^{(y)} \\
        & + l_i(1)\mathbf{F}^*(1, y_j)\cdot (\widehat{x}) \: w_j^{(y)}
	\end{split}
\end{equation}

Note that the integrands are also of order $2 N$, and are computed exactly. We put
Equations~\ref{equ:integral_1}, ~\ref{equ:integral_2} and ~\ref{equ:integral_3} in
Equation~\ref{equ:integral_equ} and divide by the weights $w_i^{ \left( x \right) } w_j^{ \left( y \right) }$.

\begin{equation} \label{equ:2d_wave_full}
	\begin{split}
        & \frac{d\mathbf{Q}(x_i, y_j)}{dt} \\
        & + \left\{ \left[ l_i \left( -1 \right) \mathbf{F}^* \left( -1, y_j \right) \cdot \left( -\widehat{x} \right) \frac{1}{w_i^{ \left( x \right) }} + l_i \left( 1 \right) \mathbf{F}^* \left( 1, y_j \right) \cdot
        \left( \widehat{x} \right) \frac{1}{w_i^{ \left( x \right) }} \right] - \sum_{k = 0}^{N} \mathbf{F} \left(x_k, y_j \right) \frac{l'_i \left( x_k \right) w_k^{ \left( x \right) }}{w_i^{ \left( x \right) }} \right\} \\
        & + \left\{ \left[ l_j \left( -1 \right) \mathbf{F}^* (x_i, -1) \cdot \left( -\widehat{y} \right) \frac{1}{w_j^{ \left( y \right) }} + l_j \left( 1 \right) \mathbf{F}^*(x_i, 1) \cdot
        \left( \widehat{y} \right) \frac{1}{w_j^{ \left( y \right) }} \right] - \sum_{l = 0}^{N} \mathbf{G} \left(x_i, y_l \right) \frac{l'_j \left( y_l \right) w_l^{ \left( y \right) }}{w_j^{ \left( y \right) }} \right\} \\
        & = 0, \quad i,j = 0, ..., N
	\end{split} 
\end{equation}

We define $l'_i(x_k)$ as the derivative matrix $D_{k i}$. Since they are constant, we also
incorporate the weights $w_i$ and $w_k$.

\begin{equation} \label{equ:d_hat}
	\begin{split}
        \widehat{D}_{i k} = & -\frac{D_{k i} w_k}{w_i} \\
        = & -\frac{l'_i(x_k) w_k}{w_i}
	\end{split} 
\end{equation}

This simplifies Equation~\ref{equ:2d_wave_full} to:

\begin{equation} \label{equ:2d_wave_d}
	\begin{split}
        & \frac{d\mathbf{Q}(x_i, y_j)}{dt} \\
        & + \left\{ \left[ l_i \left( -1 \right) \mathbf{F}^* \left( -1, y_j \right) \cdot \left( -\widehat{x} \right) \frac{1}{w_i^{ \left( x \right) }} + l_i \left( 1 \right) \mathbf{F}^* \left( 1, y_j \right) \cdot
        \left( \widehat{x} \right) \frac{1}{w_i^{ \left( x \right) }} + \sum_{k = 0}^{N} \mathbf{F} \left( x_k, y_j \right) \widehat{D}_{i k}^{ \left( x \right) } \right] \right\} \\
        & + \left \{ \left [ l_j \left( -1 \right) \mathbf{F}^* \left( x_i, -1 \right) \cdot \left( -\widehat{y} \right) \frac{1}{w_j^{ \left( y \right) }} + l_j \left( 1 \right) \mathbf{F}^* \left(x_i, 1 \right) \cdot
        \left( \widehat{y} \right) \frac{1}{w_j^{ \left( y \right) }} + \sum_{l = 0}^{N} \mathbf{G} \left( x_i, y_l \right) \widehat{D}_{j l}^{ \left( y \right) } \right] \right\} \\
        & = 0, \quad i, j = 0, ..., N
	\end{split}
\end{equation}

The collocation points, weights and derivative matrices from Equation~\ref{equ:2d_wave_d} can be
computed directly and stored for the whole computation. Algorithms for those are discussed in
Section~\ref{section:spectral_element_method:implementation}. The next section discusses the
computation of the fluxes $\mathbf{F}^*$.

\subsection{Fluxes} \label{section:spectral_element_method:dg_sem:fluxes}

We now need to compute the numerical fluxes $\mathbf{F}^*$ as a way to approximate the physical
fluxes $\mathfrak{F}$. We recall the formulation for the fluxes from
Equation~\ref{equ:2d_wave_fluxes}. 

\begin{equation} \label{equ:physical_fluxes}
	\mathfrak{F} = \mathbf{f_x} + \mathbf{g_y} = B \mathbf{q_x} + C \mathbf{q_y}
\end{equation}

With matrices $B$ and $C$ taken from Equation~\ref{equ:2d_wave_matrix}.

\begin{equation}
	B = \begin{bmatrix}
        0 & c^2 & 0 \\ 
        1 & 0 & 0 \\ 
        0 & 0 & 0 
	\end{bmatrix}
	C = \begin{bmatrix}
        0 & 0 & c^2\\ 
        0 & 0 & 0 \\ 
        1 & 0 & 0
	\end{bmatrix}
\end{equation}

We will use an upwind scheme~\cite{Toro2009} to impose the boundary conditions. On an interface
between two elements, the left and right elements in that coordinate system, the state at the
interface is the left state if the wave goes from left to right, or the right state if the wave goes
from right to left. This is the upwind state of the boundary.

Since it is not evident what the upwind state of the system as is described in
Equation~\ref{equ:physical_fluxes}, we will decouple the wave components. We start with the $x$
direction, decomposing $B$ to a diagonal matrix $\Lambda_B$, its right eigenvectors $K_B$, and their
inverse $K_B^{-1}$.

\begin{equation}
    \Lambda_B = 
    \begin{bmatrix}
        c & 0 & 0 \\ 
        0 & -c & 0 \\ 
        0 & 0 & 0
    \end{bmatrix}
    K_B = 
    \begin{bmatrix}
        c & -c & 0 \\ 
        1 & 1 & 0 \\ 
        0 & 0 & 1 
    \end{bmatrix}
    K_B^{-1} = 
    \begin{bmatrix}
        \frac{1}{2c} & \frac{1}{2} & 0 \\ 
        -\frac{1}{2c} & \frac{1}{2} & 0 \\ 
        0 & 0 & 1
    \end{bmatrix}
\end{equation}

The diagonal matrix can be further decomposed into three wave directions: left-to-right,
right-to-left, and stationary.

\begin{equation}
	\begin{split}
		\Lambda_B & = 
        \begin{bmatrix}
            c & 0 & 0 \\ 
            0 & -c & 0 \\ 
            0 & 0 & 0
		\end{bmatrix} = 
		\begin{bmatrix}
            c & 0 & 0 \\ 
            0 & 0 & 0 \\ 
            0 & 0 & 0
		\end{bmatrix} +
		\begin{bmatrix}
            0 & 0 & 0 \\ 
            0 & -c & 0 \\ 
            0 & 0 & 0
		\end{bmatrix} +
		\begin{bmatrix}
            0 & 0 & 0 \\ 
            0 & 0 & 0 \\ 
            0 & 0 & 0
		\end{bmatrix} \\
		&= \Lambda_B^+ + \Lambda_B^- + \Lambda_B^0
	\end{split}
\end{equation}

We can then split the wave into three components, each containing only one direction.

\begin{equation}
	B = K_B \Lambda_B^+ K_B^{-1} + K_B \Lambda_B^- K_B^{-1} + K_B \Lambda_B^0 K_B^{-1} = B^+ + B^- + B^0
\end{equation}

We can evaluate the flux with:

\begin{equation} \label{equ:flux_x}
	\mathbf{F} \cdot \widehat{x} = B^+\mathbf{q} + B^-\mathbf{q} + B^0 \mathbf{q}.
\end{equation}

\begin{figure}[H]
	\centering
	\includesvg[width=0.25\textwidth]{Chapter_spectral_element_method/media/waves}
	\caption{States on both sides of an interface: The normal $\widehat{n}$ of the interface
	    determines the left and right sides. $\mathbf{Q}^L$ and $\mathbf{Q}^R$ are the states on the
	    left and right of the interface, respectively. $w^+$ and $w^-$ indicate the left-to-right
	    and right-to-left waves, respectively.}
	\label{fig:waves}
\end{figure}

Figure~\ref{fig:waves} shows a boundary, with the associated states and waves. This guides us in
choosing the states $\mathbf{q}$ in Equation~\ref{equ:flux_x}. The upwind state for the
left-to-right wave is $\mathbf{Q}^L$, and the upwind state for the right-to-left wave is
$\mathbf{Q}^R$. The stationary wave only has zeros in its matrix, and can be removed. This gives us
the formulation for the numerical fluxes.

\begin{equation} \label{equ:flux_x_states}
	\mathbf{F}^* \cdot \widehat{x} = B^+ \mathbf{Q}^L + B^- \mathbf{Q}^R
\end{equation}

We can now compute the numerical fluxes. We define the characteristic variable $\mathbf{W}_B$ for
the $x$ direction.

\begin{equation}
	\mathbf{W}_B = K_B^{-1} \mathbf{q} = 
    \begin{bmatrix}
        \frac{1}{2 c} & \frac{1}{2} & 0 \\ 
        -\frac{1}{2 c} & \frac{1}{2} & 0 \\ 
        0 & 0 & 1
	\end{bmatrix}
	\begin{bmatrix}
        p \\ 
        u \\ 
        v
	\end{bmatrix} = 
	\begin{bmatrix}
        \frac{p + c u}{2 c} \\ 
        \frac{-p + c u}{2 c} \\ 
        v
	\end{bmatrix}
\end{equation}

Next we multiply with $\Lambda_B$:

\begin{equation}
	\Lambda_B \mathbf{W}_B =
	\begin{bmatrix}
        c & 0 & 0 \\ 
        0 & -c & 0 \\ 
        0 & 0 & 0
	\end{bmatrix}
	\begin{bmatrix}
        \frac{p + c u}{2 c} \\ 
        \frac{-p + c u}{2 c} \\ 
        v
	\end{bmatrix} = 
	\begin{bmatrix}
        c \cdot \frac{p^L + c u^L}{2 c} \\ 
        -c \cdot \frac{-p^R + c u^R}{2 c} \\ 
        0
	\end{bmatrix} = 
	\begin{bmatrix}
        c \cdot w_B^+ \\ 
        -c \cdot w_B^- \\ 
        0
	\end{bmatrix}
\end{equation}

The superscripts $L$ and $R$ indicate which state is used, according to
Equation~\ref{equ:flux_x_states}. We define $w_B^+$ and $w_B^-$ as the left-to-right and
right-to-left waves for the $x$ direction. Finally, multiplying by $K_B$, we get the full numerical
flux for the $x$ direction:

\begin{equation} \label{equ:waves_x}
	\begin{split}
        w_B^+ & \equiv \frac{p^L + c u^L}{2 c} \\
        w_B^- & \equiv \frac{-p^R + c u^R}{2 c},
	\end{split} 
\end{equation}

\begin{equation} \label{equ:numerical_flux_x}
	\begin{split}
        \mathbf{F}^* \cdot \widehat{x} = B \mathbf{q} = K_B \left( \Lambda_B K_B^{-1} \mathbf{q} \right) & = 
        \begin{bmatrix}
            c & -c & 0 \\ 
            1 & 1 & 0 \\ 
            0 & 0  & 1
        \end{bmatrix}
        \begin{bmatrix}
            c \cdot w_B^+ \\ 
            -c \cdot w_B^- \\ 
            0
        \end{bmatrix} \\ 
        & = \begin{bmatrix}
            c^2 \left( w_B^+ + w_B^- \right) \\ 
            c \left( w_B^+ - w_B^- \right) \\ 
            0
        \end{bmatrix} \\
        & = \begin{bmatrix}
            c \left( \frac{p^L - p^R}{2} + c \frac{u^L + u^R}{2} \right) \\ 
            \frac{p^L + p^R}{2} + c \frac{u^L - u^R}{2} \\ 
            0
        \end{bmatrix}.
	\end{split}
\end{equation}

The numerical fluxes in the $y$ direction are computed similarly. The matrix $C$ decomposes to:

\begin{equation}
	\Lambda_C = \begin{bmatrix}
        c & 0 & 0 \\ 
        0 & -c & 0 \\ 
        0 & 0 & 0
	\end{bmatrix}
	K_C = \begin{bmatrix}
        c & -c & 0 \\ 
        0 & 0 & 1 \\ 
        1 & 1 & 0 
	\end{bmatrix}
	K_C^{-1} = \begin{bmatrix}
        \frac{1}{2 c} & 0 & \frac{1}{2} \\ 
        -\frac{1}{2 c} & 0 & \frac{1}{2} \\ 
        0 & 1 & 0
	\end{bmatrix}
\end{equation}

The characteristic variables in the $y$ direction, $\mathbf{W}_C$, are:

\begin{equation}
	\mathbf{W}_C = K_C^{-1} \mathbf{q} = 
	\begin{bmatrix}
        \frac{p + c u}{2 c} \\ 
        \frac{-p + c u}{2 c} \\ 
        u
	\end{bmatrix}
\end{equation}

\noindent
with $\Lambda_C$:

\begin{equation}
    \Lambda_C \mathbf{W}_C =  
    \begin{bmatrix}
        c & 0 & 0 \\ 
        0 & -c & 0 \\ 
        0 & 0 & 0
    \end{bmatrix}
    \begin{bmatrix}
        \frac{p + c v}{2 c} \\ 
        \frac{-p + c v}{2 c} \\ 
        u
    \end{bmatrix} = 
    \begin{bmatrix}
        c \cdot \frac{p^L + c v^L}{2 c} \\ 
        -c \cdot \frac{-p^R + c v^R}{2 c} \\ 
        0
    \end{bmatrix} = 
    \begin{bmatrix}
        c \cdot w_C^+ \\ 
        -c \cdot w_C^- \\ 
        0
    \end{bmatrix},
\end{equation}

and the waves for the $y$ direction:

\begin{equation} \label{equ:waves_y}
	\begin{split}
        w_C^+ & \equiv \frac{p^L + c v^L}{2 c} \\
        w_C^- & \equiv \frac{-p^R + c v^R}{2 c}.
	\end{split} 
\end{equation}

The full numerical flux in the $y$ direction is:

\begin{equation} \label{equ:numerical_flux_y}
    \begin{split}
        \mathbf{F}^* \cdot \widehat{y} = C \mathbf{q} = K_C \left( \Lambda_C K_C^{-1} \mathbf{q} \right) & = 
        \begin{bmatrix}
            c & -c & 0 \\ 
            0 & 0 & 1 \\ 
            1 & 1  & 0
        \end{bmatrix}
        \begin{bmatrix}
            c \cdot w_C^+ \\ 
            -c \cdot w_C^- \\ 
            0
        \end{bmatrix} \\ 
        & = \begin{bmatrix}
            c^2 \left( w_C^+ + w_C^- \right) \\ 
            0 \\ 
            c \left( w_C^+ - w_C^- \right)
        \end{bmatrix} \\
        & = \begin{bmatrix}
            c \left( \frac{p^L - p^R}{2} + c \frac{v^L + v^R}{2} \right) \\ 
            0 \\ 
            \frac{p^L + p^R}{2} + c \frac{v^L - v^R}{2}
        \end{bmatrix}
    \end{split}
\end{equation}

With the two relations~\ref{equ:numerical_flux_x} and~\ref{equ:numerical_flux_y}, we can compute the
fluxes in the $x$ and $y$ directions respectively. The algorithm used to compute these fluxes is presented in
Subsection~\ref{section:spectral_element_method:implementation:fluxes}. It is commonly known as the
Riemann solver.

\subsection{Time integration} \label{section:spectral_element_method:dg_sem:time}

Now that we know how to compute the interior terms and the numerical fluxes of
Equation~\ref{equ:2d_wave_d}, we can compute the time derivative $\mathbf{Q}_t$. We then need to
integrate the equation in time. We will used a third-order low-storage Runge-Kutta method, as
described by Williamson~\cite{Williamson1980}. As the name suggests, this method uses low memory to
attain high temporal accuracy. This is especially useful in the context of GPU computation, as GPUs
tend to have less available memory than usual HPC CPU platforms. This method requires $2 N$ storage,
where $N$ is the number of variables. Concretely, we will need to store the computed time
derivatives in temporary arrays, which will then be added to the real time derivative arrays. The
truncation error is comparable to that of the usual Runge-Kutta methods~\cite{Williamson1980}.

The method works as follows. For a differential equation

\begin{equation}
	u_t = H(u, t),
\end{equation}

\noindent
we will use $\Delta t$ to represent the time step, $n$ to represent the number of time steps thus
far, and $t_n = n \Delta t$ as the current time. $u$ is the solution vector with $N$ variables, and
$U^n$ is the approximation of the solution at $t_n$. The method gives the approximation of the
solution at the next timestep as:

\begin{equation} \label{equ:runge_kutta}
	\begin{split}
		& U \leftarrow U^n \\
		& T \leftarrow H \left( U, t_n \right) \\
		& U \leftarrow U + \frac{1}{3} \Delta t G \\
		& T = -\frac{5}{9} T + H \left( U, t_n + \frac{1}{3} \Delta t \right) \\
		& U \leftarrow U + \frac{15}{16} \Delta t G \\
		& T \leftarrow -\frac{153}{128} T + H \left( U, t_n + \frac{3}{4} \Delta t \right) \\
		& U^{n + 1} \leftarrow U + \frac{8}{15} \Delta t T
	\end{split}
\end{equation}

$T$ is introduced as a temporary variable to store the time derivative after partial time steps. As
$U$ and $T$ are overwritten at each of the three stages, the storage required is only $2 N$, where
$N$ is the number of variables making up $U$. The algorithm can be summarised as the following stage
run three times, where $m$ is the stage number.

\begin{equation} \label{equ:runge_kutta_stage}
	\begin{split}
		& T \leftarrow a_m T + H \left( U, t_n + b_m \Delta t \right) \\
		& U \leftarrow U + g_m \Delta t T
	\end{split}
\end{equation}

The following table lists the coefficients $a_m$, $b_m$ and $g_m$. The algorithm used by the program
to advance the simulation in time is described in
Subsection~\ref{section:spectral_element_method:implementation:time}. 

\begin{table}[H]
	\centering
	\begin{tabular}{c c c c}
		$m$ & $a_m$ & $b_m$ & $g_m$ \\
		\hline
		0 & 0 & 0 & $\frac{1}{3}$ \\
		1 & $-\frac{5}{9}$ & $\frac{1}{3}$ & $\frac{15}{16}$ \\
		2 & $-\frac{153}{128}$ & $\frac{3}{4}$ & $\frac{8}{15}$ \\
	\end{tabular}
	\caption{Coefficients of the third-order low storage Runge-Kutta method.}
	\label{table:runge_kutta_coefficient}
\end{table}

This method is an explicit time stepping method, therefore we have to fulfill the \textit{Courant
Friedrichs Lewy (CFL)} condition on the time step size to ensure stability. The CFL condition is
stated as:

\begin{equation}
	\left| \frac{c \Delta t}{\Delta x} \right| \leq \CFL
\end{equation}

Where the $\CFL$ number is usually 1. As we have a higher-order time integration scheme, the $\CFL$
number can be increased above this number~\cite{Gottlieb2001}. % CHECK show why higher than 1?

\begin{equation}
        0 \leq \CFL \leq 1
\end{equation}

To account for the uneven spacing between the collocation points inside an element, we will estimate
the smallest spacing in an element as: 

\begin{equation}
    \Delta x = \frac{\Delta x_{k}}{N^2}
\end{equation}

Where $\Delta x_{k}$ is the length of element $k$, and $N$ is the polynomial order of that element.
The global timestep will be chosen as the minimum timestep of all elemental timesteps. 

\begin{equation}
    \Delta t = \min_{k \in 0:K} \left( \Delta t_k \right)
\end{equation}

\begin{equation}
    \Delta t_k \leq \CFL \frac{c \Delta x_{k}}{N^2}
\end{equation}

\section{Implementation} \label{section:spectral_element_method:implementation}
% Talk about the flux computation, possible race conditions

\subsection{Fluxes} \label{section:spectral_element_method:implementation:fluxes}

\subsection{Time integration} \label{section:spectral_element_method:implementation:time}
